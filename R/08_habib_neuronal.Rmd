---
title: "08 Habib Neuronal"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/08-habib-neuronal.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

In this document we apply additional processing on the cleaned dataset derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq), which uses droplet-based UMI data from @habib_massively_2017.
We then subset and analyze the neuronal population of cells.
We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd",
  "SC3", "DT", "data.table", "Seurat", "uwot", "viridis")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "08"))) {
  dir.create(file.path(assets_dir, "cache", "08"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "08"))) {
  dir.create(file.path(results_dir, "data", "08"), recursive = TRUE)}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_viridis()}
  gg}
```

# QC

We use a version of the dataset that has not had data removed from the original in order to make a new attempt at QC.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce_orig.rds"))
sce
```

## Low Quality Nuclei

We remove nuclei overabundant in mitochondrial/ribosomal gene expression, a common indicator of low quality nuclei.

```{r}
mito_drop <- isOutlier(sce$pct_counts_mito, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_ribo, nmads = 3, type = "higher")
keep <- !(mito_drop | ribo_drop)
datatable(data.table(
  "By Mitochondrial" = sum(mito_drop), "By Ribosomal" = sum(ribo_drop),
  Remaining = sum(keep)))
sce <- sce[ , keep]
dim(sce)[2]
```

## Lowly Expressed Genes

We consider the expression profile of genes each time nuclei are removed.
A distinctly negative skew can be seen due to lowly expressed genes in our dataset.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

Therefore, we remove genes in the manner specified in @habib_massively_2017.

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it.
For each analysis, genes were removed that were detected in less than 10 nuclei.

```{r}
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

We see a robust improvement in normality.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

We then display some additional summary statistics.
Apparent is the disproportionately high expression of encoding lncRNAs MALAT1 and MEG3, both of which are known to have higher expression in nuclei, as noted in @habib_massively_2017.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
plotExprsFreqVsMean(sce)
```

## Normalization

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell types/sizes, producing "size factor" values that indicate the extent to which nuclei should be scaled.
We also perform a rough clustering of our nuclei, which improves accuracy on highly heterogenous data such as that from the brain.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "08", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "08", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

In an experiment where most systematic differences between nuclei are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size.

```{r}
sce <- size_factors
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are well correlated, confirming the source of bias.
We therefore add normalized expression data to our SCE object using the calculated size factors.

```{r}
sce <- normalize(sce)
sce
```

# Dimensionality Reduction

## Technical Summation + UMAP

We start by applying `denoisePCA` from the `scran` package, which can automatically select the number of PCs to retain by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "08", "denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  set.seed(1)
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

The results suggest retaining the following number of PCs:

```{r}
sce <- pca
ncol(reducedDim(sce, "PCA"))
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = ncol(reducedDim(sce, "PCA")), lty = 2, col = "red")
```

We assess the effectiveness of these PCs by using them to compute UMAP coordinates.

```{r}
rds <- file.path(assets_dir, "cache", "08", "denoise_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- runUMAP(sce, min_dist = 0.75)
  saveRDS(umap, rds)}
```

```{r}
sce <- umap
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("denoise_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_umap1 = add_df$denoise_umap1, denoise_umap2 = add_df$denoise_umap2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster_name")],
  add_df)
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_umap1 = median(denoise_umap1), denoise_umap2 = median(denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) denoisePCA UMAP")
```
