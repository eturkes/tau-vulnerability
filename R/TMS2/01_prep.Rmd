---
title: '01 Prep - `r unlist(strsplit(getwd(), "/"))[6]`'
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: '../../`r unlist(strsplit(getwd(), "/"))[4]`.bib'
link-citations: true
output:
  html_document:
    code_folding: hide
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(
    "..", "..", "results", unlist(strsplit(getwd(), "/"))[6], "01-prep.html"
  ))})
---

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).

In this particular document we prepare the raw data for downstream analysis.
The data here is derived from @`r unlist(strsplit(getwd(), "/"))[6]` and will be referenced using the name ``r unlist(strsplit(getwd(), "/"))[6]``.

```{r}
# Load in necessary boilerplate and libraries.
# --------------------------------------------

#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

# These should be checked per document.
# ------------------------------------------

packages <- c(
  "conflicted", "BiocFileCache", "SingleCellExperiment", "biomaRt", "dplyr", "ggplot2", "ggrepel",
  "scater", "DT", "data.table", "DropletUtils", "Seurat", "future"
)
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))
source(file.path(getwd(), "..", "utils.R"))

analysis_no <- 1
protocol_type <- "droplet"
download_name <- "allneurons_integrated" # Name of download file corresponding to dataset.

knitr::opts_chunk$set(fig.width = 15, fig.height = 13)
options(stringsAsFactors = FALSE)
plan("multiprocess") # Parallel processing for Seurat.

# Everything else in this chunk remains generally unchanged.
# ----------------------------------------------------------

data_name <- unlist(strsplit(getwd(), "/"))[6] # Name of dataset.
data_name_stem <- unlist(strsplit(data_name, "-"))[1] # `data_name` up to the first hyphen.
data_dir <- file.path(getwd(), "..", "..", "data", data_name) # Publicly available data.
assets_dir <- file.path(getwd(), "..", "..", "assets", data_name) # Misc binaries and temp files.
results_dir <- file.path(getwd(), "..", "..", "results", data_name)

# Unique cache and results directory for each analysis number.
if (!dir.exists(file.path(assets_dir, "cache", paste0("0", analysis_no)))) {
  dir.create(file.path(assets_dir, "cache", paste0("0", analysis_no)), recursive = TRUE)
}
if (!dir.exists(file.path(results_dir, "data", paste0("0", analysis_no)))) {
  dir.create(file.path(results_dir, "data", paste0("0", analysis_no)), recursive = TRUE)
}
```

# Cleaning

Here we do any data wrangling neccessary to transform the data into more convenient formats for downstream analysis.

```{r}
seurat <- readRDS(file.path(assets_dir, paste0(download_name, ".rds")))
DefaultAssay(seurat) <- "RNA" # Don't use `SCT` or `integrated` data.

# Move some things into metadata.
seurat[[paste0(data_name_stem, "_clusters_name")]] <- Idents(seurat)
seurat$batch <- seurat$subject
add_df <- data.frame(Embeddings(seurat, reduction = "umap"))
names(add_df) <- paste0("umap", seq(ncol(add_df)))
seurat[[paste0(data_name_stem, "_umap", 1)]] <- add_df$umap1
seurat[[paste0(data_name_stem, "_umap", 2)]] <- add_df$umap2

sce <- as.SingleCellExperiment(seurat)
sce
```

## Subset to Controls

```{r}
keep <- grepl("NDC", sce$pathology)
sce <- sce[ , keep]
sce
```

## Gene Annotations

We additional identifiers, which are useful for resolving ambiguity in gene symbols and are required for some packages.

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "gene_anno.rds")
if (file.exists(rds)) {
  gene_anno <- readRDS(rds)
} else {
  mart <- useEnsembl(biomart = "ensembl", dataset = "hsapiens_gene_ensembl")
  attributes <- c(
    "external_gene_name", "ensembl_gene_id", "entrezgene_id",
    "hgnc_symbol", "description", "chromosome_name"
  )
  gene_anno <- getBM(
    attributes = attributes, filters = "external_gene_name", values = rownames(sce), mart = mart
  )
  rm(mart)
  saveRDS(gene_anno, rds)
}

# Remove genes not in the RNA-seq dataset.
keep <- which(gene_anno$external_gene_name %in% rownames(sce))
gene_anno <- gene_anno[keep, ]

# Remove annotations to scaffolds, assembly patches, and alternative loci.
chromosomes <- c(1:22, "X", "Y", "MT")
gene_anno <- gene_anno[which(gene_anno$chromosome_name %in% chromosomes), ]

# Remove duplicates.
dup <- table(gene_anno$external_gene_name)
dup <- sort(dup[dup > 1], decreasing = TRUE)
dup <- which(gene_anno$external_gene_name %in% names(dup))
gene_anno2 <- gene_anno[dup, ]
gene_anno2 <- gene_anno2[which(gene_anno2$hgnc_symbol == gene_anno2$external_gene_name), ]
gene_anno2 <- distinct(gene_anno2, external_gene_name, .keep_all = TRUE) # Random selection method.
gene_anno <- rbind(gene_anno[-dup, ], gene_anno2)

# Remove missing.
keep <- match(gene_anno$external_gene_name, rownames(sce))
sce <- sce[keep, ]

rowData(sce) <- gene_anno
rm(gene_anno, gene_anno2)
names(rowData(sce))
```

# Exploration

We take a look at the data in its cleaned form.

## Clusters

```{r}
red_dim_plot(
  sce, paste0(data_name_stem, "_umap", 1), paste0(data_name_stem, "_umap", 2),
  paste0(data_name_stem, "_clusters_name"), "cat"
)
```

## Samples

```{r}
red_dim_plot(sce, paste0(data_name_stem, "_umap", 1), paste0(data_name_stem, "_umap", 2), "batch")
```

# QC

First, we add QC metric metadata to the SCE object.
We also set aside a copy of the object for a version with metrics but no removal performed.

```{r}
ribo_genes <- read.table(
  file.path(getwd(), "..", "..", "hugo-ribo-genes.txt"), sep = "\t", header = TRUE
)
is_ribo <- which(rowData(sce)$external_gene_name %in% ribo_genes$Approved.symbol)
is_mito <- which(rowData(sce)$chromosome_name == "MT")

sce <- addPerCellQC(sce, subsets = list(ribo = is_ribo, mito = is_mito), BPPARAM = MulticoreParam())
sce <- addPerFeatureQC(sce, BPPARAM = MulticoreParam())

sce_metric <- sce

names(colData(sce))
names(rowData(sce))
```

## Adaptive Thresholds

```{r}
remove <- quickPerCellQC(
  sce, percent_subsets = c("subsets_mito_percent", "subsets_ribo_percent"), batch = sce$batch
)
sce$discard <- remove$discard
datatable_custom(t(colSums(as.matrix(remove))))
```

We also check if the removals correlate with upregulated genes, in which case caution is advised as we may remove a biologically interesting population.

```{r}
lost <- calculateAverage((sce)[ , !sce$discard])
kept <- calculateAverage((sce)[ , sce$discard])
logged <- edgeR::cpm(cbind(lost, kept), log = TRUE, prior.count = 2) # `edgeR` conflicts with SCE.
logFC <- logged[ , 1] - logged[ , 2]
abundance <- rowMeans(logged)
rm(logged)

plot(abundance, logFC, xlab = "Average Count", ylab = "LogFC (lost/kept)", pch = 16)
points(abundance[is_mito], logFC[is_mito], col = "dodgerblue", pch = 16)
```

They do not, so we perform the removal.

```{r}
sce <- sce[ , !sce$discard]
dim(sce)
```

## Protocol Specific

Here we carry out any protocol specific techniques, such as identification of empty droplets in a droplet-based experiment.
The steps carried out are designated by a boolean at the beginning of this report.

```{r}
# TODO: Automate reporting of results.
if (protocol_type == "droplet") {
  # Identify empty droplets as those with a low UMI count.
  bcrank <- barcodeRanks(counts(sce))
  uniq <- !duplicated(bcrank$rank) # Only show unique points for plotting speed.
  plot(
    bcrank$rank[uniq], bcrank$total[uniq], log = "xy",
    xlab = "Rank", ylab = "Total UMI count", cex.lab = 1.2
  )
  abline(h = metadata(bcrank)$inflection, col = "darkgreen", lty = 2)
  abline(h = metadata(bcrank)$knee, col = "dodgerblue", lty = 2)
  legend(
    "bottomleft", legend = c("Inflection", "Knee"), col = c("darkgreen", "dodgerblue"),
    lty = 2, cex = 1.2
  )
}
```

# Normalization

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "sctransform.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- as.Seurat(sce, data = NULL)
  seurat <- NormalizeData(seurat, verbose = FALSE)
  seurat <- ScaleData(seurat, verbose = FALSE)

  # Saves into new assay `SCT` while previous data is retained in `RNA`.
  # Note that this function produces many iterations of the following benign warning:
  # Warning in theta.ml(y = y, mu = fit$fitted): iteration limit reached
  seurat <- SCTransform(
    seurat, vars.to.regress = c("subsets_mito_percent", "subsets_ribo_percent"), verbose = FALSE
  )

  saveRDS(seurat, rds)
}

rm(sce)
seurat
```

# Dimensionality Reduction

## PCA

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "pca.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- RunPCA(seurat, verbose = FALSE)
  add_df <- data.frame(Embeddings(seurat, reduction = "pca")[ , 1:2])
  names(add_df) <- paste0("pca", seq(ncol(add_df)))
  seurat$pca1 <- add_df$pca1
  seurat$pca2 <- add_df$pca2
  saveRDS(seurat, rds)
}

ElbowPlot(seurat)

red_dim_plot(seurat, "pca1", "pca2", paste0(data_name_stem, "_clusters_name"))
red_dim_plot(seurat, "pca1", "pca2", "batch")

VizDimLoadings(seurat, dims = 1:2)
DimHeatmap(seurat, dims = 1:15, ncol = 3) # TODO: Customize color.
```

## UMAP

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "umap.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- RunUMAP(seurat, dims = 1:30, min.dist = 0.5, verbose = FALSE)
  add_df <- data.frame(Embeddings(seurat, reduction = "umap"))
  names(add_df) <- paste0("umap", seq(ncol(add_df)))
  seurat$umap1 <- add_df$umap1
  seurat$umap2 <- add_df$umap2
  saveRDS(seurat, rds)
}

red_dim_plot(seurat, "umap1", "umap2", paste0(data_name_stem, "_clusters_name"), "cat")
red_dim_plot(seurat, "umap1", "umap2", "batch")
```

# Clustering

```{r}
resolution <- (dim(seurat)[2] / 3000) * 0.8 # Default of 0.8 optimal for 3K cells so we scale it.

# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "clusters.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- FindNeighbors(seurat, dims = 1:30, verbose = FALSE)
  seurat <- FindClusters(seurat, resolution = resolution, verbose = FALSE)
  saveRDS(seurat, rds)
}

print(paste0("Seurat resolution is: ", resolution))
red_dim_plot(seurat, "umap1", "umap2", "seurat_clusters", "cat")
```

# DEGs

In this section, we calculate differentially expressed genes (DEGs) and identify marker genes for each cluster.

```{r}
# TODO: Reduce hardcoding in rest of chunk.
# -----------------------------------------

DefaultAssay(seurat) <- "RNA" # It is currently recommended to use the `RNA` assay for DEGs.

# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "markers.rds")
if (file.exists(rds)) {
  markers <- readRDS(rds)
} else {
  markers <- FindAllMarkers(seurat, only.pos = TRUE, verbose = FALSE)
  saveRDS(markers, rds)
}

top <- markers %>% group_by(cluster) %>% top_n(n = 3, wt = avg_logFC)
DoHeatmap(seurat, features = top$gene, size = 1.5) + # TODO: Customize color.
  NoLegend()

top <- markers %>% group_by(cluster) %>% top_n(n = 1, wt = avg_logFC)
datatable_custom(top)

VlnPlot(seurat, features = top$gene[1:9], ncol = 3)
VlnPlot(seurat, features = top$gene[10:18], ncol = 3)
VlnPlot(seurat, features = top$gene[19:27], ncol = 3)
VlnPlot(seurat, features = top$gene[28:36], ncol = 3)

FeaturePlot(
  seurat, features = top$gene[1:9], order = TRUE, reduction = "umap",
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 3
)
FeaturePlot(
  seurat, features = top$gene[10:18], order = TRUE, reduction = "umap",
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 3
)
FeaturePlot(
  seurat, features = top$gene[19:27], order = TRUE, reduction = "umap",
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 3
)
FeaturePlot(
  seurat, features = top$gene[28:36], order = TRUE, reduction = "umap",
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 3
)

DotPlot(seurat, features = unique(top$gene), cols = c("blue", "red")) + RotatedAxis()

datatable_custom(markers %>% group_by(cluster) %>% top_n(n = 15, wt = avg_logFC))
```

# References

This is the concluding section of the document. Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
saveRDS(sce_metric, file.path(results_dir, "data", paste0("0", analysis_no), "sce_metric.rds"))
saveRDS(seurat, file.path(results_dir, "data", paste0("0", analysis_no), "seurat.rds"))
saveRDS(markers, file.path(results_dir, "data", paste0("0", analysis_no), "markers.rds"))

sessionInfo()
```
