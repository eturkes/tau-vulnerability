---
title: '01 Prep - `r unlist(strsplit(getwd(), "/"))[6]`'
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: '../../`r unlist(strsplit(getwd(), "/"))[4]`.bib'
link-citations: true
output:
  html_document:
    code_folding: hide
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(
    "..", "..", "results", unlist(strsplit(getwd(), "/"))[6], "01-prep.html"
  ))})
---

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/transcriptomics-benchmarks).

In this document prepare the raw data for downstream analysis.
The data here is derived from @`r unlist(strsplit(getwd(), "/"))[6]` and will be referenced using the name ``r unlist(strsplit(getwd(), "/"))[6]``.

```{r}
# Load in necessary boilerplate and libraries.
# --------------------------------------------

#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

analysis_no <- 1
protocol_type <- "droplet"
data_name <- unlist(strsplit(getwd(), "/"))[6] # Name of dataset.
data_name_stem <- unlist(strsplit(data_name, "-"))[1] # `data_name` up to the first hyphen.
download_name <- "GTEx_droncseq_hip_pcf" # Name of download file corresponding to dataset.
data_dir <- file.path(getwd(), "..", "..", "data", data_name) # Publicly available data.
assets_dir <- file.path(getwd(), "..", "..", "assets", data_name) # Misc binaries and temp files.
results_dir <- file.path(getwd(), "..", "..", "results", data_name)

# Unique cache and results directory for each analysis number.
if (!dir.exists(file.path(assets_dir, "cache", paste0("0", analysis_no)))) {
  dir.create(file.path(assets_dir, "cache", paste0("0", analysis_no)), recursive = TRUE)
}
if (!dir.exists(file.path(results_dir, "data", paste0("0", analysis_no)))) {
  dir.create(file.path(results_dir, "data", paste0("0", analysis_no)), recursive = TRUE)
}

packages <- c(
  "conflicted", "BiocFileCache", "SingleCellExperiment", "biomaRt", "dplyr", "ggplot2", "ggrepel",
  "scater", "DT", "data.table", "DropletUtils", "Seurat", "future"
)
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))
source(file.path(getwd(), "..", "utils.R"))

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
options(stringsAsFactors = FALSE)
plan("multiprocess") # Parallel processing for Seurat.
```

# Cleaning

Here we do any data wrangling neccessary to transform the data into more convenient formats for downstream analysis.

```{r}
# Download data using `BiocFileCache`.
data <- bfcrpath(BiocFileCache(data_dir, ask = FALSE), file.path(
  "https://storage.googleapis.com/gtex_additional_datasets/single_cell_data",
  paste0(download_name, ".tar")
))
untar(data, exdir = tempdir())

counts <- fread(
  file.path(tempdir(), download_name, paste0(download_name, ".umi_counts.txt.gz")),
  data.table = FALSE
)

# Move genes out of matrix.
rownames(counts) <- counts[ , 1]
counts <- as.matrix(counts[ , -1])

# Define each batch by the common stem of sample names.
batch <- sapply(colnames(counts), function(xx) strsplit(xx, "_")[[1]][1], USE.NAMES = FALSE)

# Prepare `colData` for SingleCellExperiment object.
colData <- data.frame(sample = colnames(counts), batch = batch, check.names = FALSE)

counts <- Matrix::Matrix(counts, sparse = TRUE) # `Matrix` conflicts with `SingleCellExperiment`.

# The original clusters file, `GTEx_droncseq_hip_pcf.clusters.txt`, has several inconsistencies.
# Specifically in clusters 15-18, which do not match those in the original publication.
# Therefore we use Supplementary Table 7 (nmeth.4407-S10.xlsx), which does not have those issues.
# However, because cluster 11 is incorrectly named in this table, we must correct that.
# Also, as this file contained non-standard formatting, some manual editing was done for use in R.
cluster <- fread(
  file.path(assets_dir, "nmeth.4407-S10-edited.txt"),
  data.table = FALSE
)

# Fix mislabeled cluster and give unique names for unclassified clusters.
for (i in seq_len(nrow(cluster))) {
  if (cluster[i, 4] == 11) {
    cluster[i, 5] <- "ODC2"
  } else if (cluster[i, 4] == 16) {
    cluster[i, 5] <- "Unlabeled1"
  } else if (cluster[i, 4] == 17) {
    cluster[i, 5] <- "Unlabeled2"
  } else if (cluster[i, 4] == 18) {
    cluster[i, 5] <- "Unlabeled3"
  }
}

# Clean up `cluster` and align rows to those in `colData`.
cluster <- cluster[ , -c(2:3)]
names(cluster) <- c(
  "sample", paste0(data_name_stem, "_cluster"), paste0(data_name_stem, "_cluster_name")
)
cluster[[paste0(data_name_stem, "_cluster")]] <- factor(
  cluster[[paste0(data_name_stem, "_cluster")]]
)
cluster <- cluster[match(colData$sample, cluster$sample), ]
rownames(cluster) <- NULL

tsne <- fread(
  file.path(tempdir(), download_name, paste0(download_name, ".tsne.txt.gz")),
  data.table = FALSE
)

names(tsne) <- c("sample", paste0(data_name_stem, "_tsne", 1:2))

colData <- cbind(colData, tsne[ , names(tsne) != "sample"], cluster[ , names(cluster) != "sample"])
sce <- SingleCellExperiment(assays = list(counts = counts), colData = colData)
rm(counts, cluster, tsne, colData)
sce
```

## Gene Annotations

We additional identifiers, which are useful for resolving ambiguity in gene symbols and are required for some packages.

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "gene_anno.rds")
if (file.exists(rds)) {
  gene_anno <- readRDS(rds)
} else {
  # Transcripts were aligned to hg19 in the original publication.
  # GRCh37 is the near equivalent available from Ensembl.
  mart <- useEnsembl(biomart = "ensembl", GRCh = 37, dataset = "hsapiens_gene_ensembl")

  attributes <- c(
    "external_gene_name", "ensembl_gene_id", "entrezgene_id",
    "hgnc_symbol", "description", "chromosome_name"
  )
  gene_anno <- getBM(
    attributes = attributes, filters = "external_gene_name", values = rownames(sce), mart = mart
  )
  rm(mart)
  saveRDS(gene_anno, rds)
}

# Remove genes not in the RNA-seq dataset.
remove_genes <- which(!gene_anno$external_gene_name %in% rownames(sce))
gene_anno <- gene_anno[-remove_genes, ]

# Remove annotations to scaffolds, assembly patches, and alternative loci.
chromosomes <- c(1:22, "X", "Y", "MT")
gene_anno <- gene_anno[which(gene_anno$chromosome_name %in% chromosomes), ]

# Remove duplicates.
dup <- table(gene_anno$external_gene_name)
dup <- sort(dup[dup > 1], decreasing = TRUE)
dup <- which(gene_anno$external_gene_name %in% names(dup))
gene_anno2 <- gene_anno[dup, ]
gene_anno2 <- gene_anno2[which(gene_anno2$hgnc_symbol == gene_anno2$external_gene_name), ]
gene_anno2 <- distinct(gene_anno2, external_gene_name, .keep_all = TRUE) # Random selection method.
gene_anno <- rbind(gene_anno[-dup, ], gene_anno2)

# Remove missing.
keep_genes <- match(gene_anno$external_gene_name, rownames(sce))
sce <- sce[keep_genes, ]

rowData(sce) <- gene_anno
rm(gene_anno, gene_anno2)
names(rowData(sce))
```

# Exploration

We take a look at the data in its cleaned form.

## Clusters

```{r}
red_dim_plot(
  sce, paste0(data_name_stem, "_tsne", 1), paste0(data_name_stem, "_tsne", 2),
  paste0(data_name_stem, "_cluster_name"), "cat"
)
```

## Samples

```{r}
red_dim_plot(
  sce, paste0(data_name_stem, "_tsne", 1), paste0(data_name_stem, "_tsne", 2),
  "batch"
)
```

# QC

First, we add QC metric metadata to the SCE object.
We also set aside a copy of the object for a version with metrics but no removal performed.

```{r}
ribo_genes <- read.table(
  file.path(getwd(), "..", "..", "hugo-ribo-genes.txt"), sep = "\t", header = TRUE
)
is_ribo <- which(rowData(sce)$external_gene_name %in% ribo_genes$Approved.symbol)
is_mito <- which(rowData(sce)$chromosome_name == "MT")
rm(ribo_genes)

sce <- addPerCellQC(sce, subsets = list(ribo = is_ribo, mito = is_mito), BPPARAM = MulticoreParam())
sce <- addPerFeatureQC(sce, BPPARAM = MulticoreParam())

sce_metric <- sce

names(colData(sce))
names(rowData(sce))
```

## Adaptive Thresholds

```{r}
remove <- quickPerCellQC(
  sce, percent_subsets = c("subsets_mito_percent", "subsets_ribo_percent"), batch = sce$batch
)
sce$discard <- remove$discard
datatable_custom(t(colSums(as.matrix(remove))))
```

We also check if the removals correlate with upregulated genes, in which case caution is advised as we may remove a biologically interesting population.

```{r}
lost <- calculateAverage((sce)[ , !sce$discard])
kept <- calculateAverage((sce)[ , sce$discard])
logged <- edgeR::cpm(cbind(lost, kept), log = TRUE, prior.count = 2) # `edgeR` conflicts with SCE.
logFC <- logged[ , 1] - logged[ , 2]
abundance <- rowMeans(logged)
rm(logged)

plot(abundance, logFC, xlab = "Average Count", ylab = "LogFC (lost/kept)", pch = 16)
points(abundance[is_mito], logFC[is_mito], col = "dodgerblue", pch = 16)
```

## Protocol Specific

Here we carry out any protocol specific techniques, such as identification of empty droplets in a droplet-based experiment.
The steps carried out are designated by a boolean at the beginning of this report.

```{r}
if (protocol_type == "droplet") {
  # Identify empty droplets as those with a low UMI count.
  bcrank <- barcodeRanks(counts(sce))
  uniq <- !duplicated(bcrank$rank) # Only show unique points for plotting speed.
  plot(
    bcrank$rank[uniq], bcrank$total[uniq], log = "xy",
    xlab = "Rank", ylab = "Total UMI count", cex.lab = 1.2
  )
  abline(h = metadata(bcrank)$inflection, col = "darkgreen", lty = 2)
  abline(h = metadata(bcrank)$knee, col = "dodgerblue", lty = 2)
  legend(
    "bottomleft", legend = c("Inflection", "Knee"), col = c("darkgreen", "dodgerblue"),
    lty = 2, cex = 1.2
  )
}
```

## Removal

```{r}
sce <- sce[ , !sce$discard]
dim(sce)
```

## sctransform

We use an advanced normalization method available in Seurat that also returns HVGs (3,000 by default) as well as regression against confounding factors.

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "sctransform.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- as.Seurat(sce, data = NULL, verbose = FALSE)
  seurat <- SCTransform(
    seurat, vars.to.regress = c("subsets_mito_percent", "subsets_ribo_percent"), verbose = FALSE
  )
  saveRDS(seurat, rds)
}
seurat
```

# Dimensionality Reduction

## PCA

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "pca.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- RunPCA(seurat, verbose = FALSE)
  add_df <- data.frame(Embeddings(seurat, reduction = "pca")[ , 1:2])
  names(add_df) <- paste0("pca", seq(ncol(add_df)))
  seurat$pca1 <- add_df$pca1
  seurat$pca2 <- add_df$pca2
  saveRDS(seurat, rds)
}

ElbowPlot(seurat)

PCAPlot(seurat, group.by = paste0(data_name_stem, "_cluster_name"))
PCAPlot(seurat, group.by = "batch")

VizDimLoadings(seurat, dims = 1:2)
DimHeatmap(seurat, dims = 1:9)
```

## UMAP

```{r}
# Cache the results.
rds <- file.path(assets_dir, "cache", paste0("0", analysis_no), "umap.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- RunUMAP(seurat, dims = 1:30, verbose = FALSE)
  add_df <- data.frame(Embeddings(seurat, reduction = "umap"))
  names(add_df) <- paste0("umap", seq(ncol(add_df)))
  seurat$umap1 <- add_df$umap1
  seurat$umap2 <- add_df$umap2
  saveRDS(seurat, rds)
}

red_dim_plot(seurat, "umap1", "umap2", paste0(data_name_stem, "_cluster_name"), "cat")
red_dim_plot(seurat, "umap1", "umap2", "batch")
```
