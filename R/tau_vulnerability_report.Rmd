---
title: "Tau Vulnerability Report"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/tau-vulnerability-report.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This is an in-depth analysis to characterize differential vulnerability to tauopathy.*

The background for this data is as follows:

- snRNAseq data from @habib_massively_2017 cleaned and analyzed in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq).

This analysis was performed in R except where noted.
The source code and instructions for rerunning the analysis can be found at [github.com/eturkes/tau-vulnerability](https://github.com/eturkes/tau-vulnerability).

# Final Results

**Read just this section for the final results of the analysis and a summary of the methods.**

# ~~~ Breakdown of Methods ~~~ {-}

**Sections from here to the end break down the methods used and are optional to read.**

We start by loading in any required packages and setting some global variables.

```{r}
packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "knitr", "kableExtra", "scran", "BiocSingular", "scater",
  "Rtsne", "svd", "SC3", "DT", "data.table", "Seurat", "uwot")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_gradient(low = "blue", high = "red")}
  gg}

# From SC3 source, needed to look at more marker genes than the top 10.
organise_marker_genes <- function(object, k, p_val, auroc) {
  dat <- rowData(object)[ , c(
    paste0("sc3_", k, "_markers_clusts"), paste0("sc3_", k, "_markers_auroc"),
    paste0("sc3_", k, "_markers_padj"), "feature_symbol")]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_padj")] < p_val & !is.na(
    dat[, paste0("sc3_", k, "_markers_padj")]), ]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_auroc")] > auroc, ]
  d <- NULL
  for (i in sort(unique(dat[, paste0("sc3_", k, "_markers_clusts")]))) {
    tmp <- dat[dat[, paste0("sc3_", k, "_markers_clusts")] == i, ]
    tmp <- tmp[order(tmp[, paste0("sc3_", k, "_markers_auroc")], decreasing = TRUE), ]
    d <- rbind(d, tmp)}
  if (nrow(dat) > 0) {
    return(d)
  } else {
    return(NULL)}}

# Adds download buttons and exponential values.
datatable_custom <- function(dt) {
  datatable(
    dt,
    extensions = "Buttons", options = list(dom = "Blfrtip", buttons = list(
      "copy", "print",
      list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download")),
    rowCallback = JS(
      "function(row, data) {for (i = 1; i < data.length; i++) {if (data[i]>1000 | data[i]<1) {",
        "$('td:eq('+i+')', row).html(data[i].toExponential(2));",
      "}}}")))}
```

# Original Data

We start by reading in data from previous broad analyses and displaying their final results.

## Habib 2017 snRNAseq {.tabset}

The cleaned dataset here is derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq), which uses droplet-based UMI data from @habib_massively_2017.
As cluster labels and tSNE coordinates were released by the authors, the main figure was recreated in the analysis, along with a successful attempt at replicating that data.
Please see the analysis for details of the processing, which was performed in close accordance to what was done in @habib_massively_2017.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce.rds"))
sce

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    paste0("habib_tsne", 1:2), paste0("hvg_svd_tsne", 1:2), "habib_cluster_name",
    "km_18_clusters_name", "seurat_clusters_name")])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
gg_df$km_18_clusters_name <- factor(gg_df$km_18_clusters_name)
gg_df$seurat_clusters_name <- factor(gg_df$seurat_clusters_name)
rm(sce)
```

### Habib Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
```

### KM 18 Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters Habib tSNE")
```

### Seurat Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "seurat_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Seurat Clusters Habib tSNE")
```

### Seurat Clusters Seurat tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "seurat_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Seurat Clusters HVG SVD tSNE")
```

### KM 18 Clusters HVG SVD tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("KM 18 Clusters HVG SVD tSNE")
```

### Habib Clusters HVG SVD tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG SVD tSNE")
```

# Habib 2017 snRNAseq

The following subsections work with data derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq).

```{r}
# Create a unique cache for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache1"))) {
  dir.create(file.path(assets_dir, "cache1"))}

sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce_orig.rds"))
sce
```

## Additional Processing

Further modifications to the data before subsetting to points of interest.

### QC

We remove nuclei overabundant in mitochondrial/ribosomal gene expression, a common indicator of low quality nuclei.

```{r}
mito_drop <- isOutlier(sce$pct_counts_mito, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_ribo, nmads = 3, type = "higher")
keep <- !(mito_drop | ribo_drop)
datatable(data.table(
  "By Mitochondrial" = sum(mito_drop), "By Ribosomal" = sum(ribo_drop),
  Remaining = sum(keep)))
sce <- sce[ , keep]
dim(sce)
```

Removal of lowly expressed genes has significant effects on downstream analysis, particularly for differential expression, as shown in @soneson_bias_2018.
It can be seen that the presence of these genes creates a distinctly negative skew.

```{r, fig.height = 6}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

Therefore, we remove genes in the manner specified in @habib_massively_2017.

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it.
For each analysis, genes were removed that were detected in less than 10 nuclei.

```{r}
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
head(rowData(sce)$n_cells_by_counts[order(rowData(sce)$n_cells_by_counts)])
dim(sce)
```

We see a robust improvement in normality.

```{r, fig.height = 6}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

We then display some additional summary statistics.
Apparent is the disproportionately high expression of encoding lncRNAs MALAT1 and MEG3, both of which are known to have higher expression in nuclei, as noted in @habib_massively_2017.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
plotExprsFreqVsMean(sce)
```

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell/nuclei types/sizes [@l_lun_pooling_2016], producing "size factor" values that indicate the extent to which a cell/nucleus should be scaled.
We also perform a rough clustering of our nuclei, which improves accuracy on highly heterogenous sets.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  quickCluster <- quickCluster(sce, use.ranks = FALSE, min.mean = 0.1, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

As additional QC, we remove those nuclei with size factors less than 0.01.

```{r}
sce <- size_factors
sce <- sce[ , which(sizeFactors(sce) >= 0.01)]
```

In an experiment where most systematic differences between nuclei are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size.

```{r}
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are well correlated, confirming the source of bias.
We therefore add normalized expression data to our SCE object using the calculated size factors.

```{r}
sce <- normalize(sce)
sce
```

### Dimensionality Reduction

We generate tSNE coordinates using PCs extracted from the calculation of a truncated SVD (singular value decomposition).
This approach was found to have high accuracy in a preprint review of PCA methods for scRNAseq [@tsuyuzaki_benchmarking_2019].
We start by applying `denoisePCA` from the `scran` package, which automatically selects PCs by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "denoise_pca.rds")
if (file.exists(rds)) {
  denoise_pca <- readRDS(rds)
} else {
  denoise_pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(denoise_pca, rds)}
```

```{r}
sce <- denoise_pca
add_df <- data.frame(reducedDim(sce, "PCA"))
names(add_df) <- paste0("denoise_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_pc1 = add_df$denoise_pc1, denoise_pc2 = add_df$denoise_pc2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "sample", "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster", "habib_cluster_name")],
  add_df[1:2])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
```

We use the first 32 PCs, chosen by visually identifying the dropoff in variance explained.

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 32, lty = 2, col = "red")
```

Now we can start to calculate the SVD from which PCs will be extracted.

```{r}
edat <- t(as.matrix(logcounts(sce)))
edat <- scale(edat)
```

We set the desired eigentriples to the number of components selected after inspecting the `denoisePCA` results.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 32)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("svd_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_pc1 = add_df$svd_pc1, svd_pc2 = add_df$svd_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
```

From these PCs we create UMAP coordinates, which often preserve global structure better than tSNE.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 100)
  saveRDS(tsne, rds)}
```

```{r}
rds <- file.path(assets_dir, "cache1", "svd_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(svd_pca, min_dist = 0.5)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = svd_pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("svd_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_umap1 = add_df$svd_umap1, svd_umap2 = add_df$svd_umap2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(svd_umap1 = median(svd_umap1), svd_umap2 = median(svd_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_umap1", y = "svd_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters SVD UMAP")
```

### Clustering

We create 17 k-means clusters, the same in @habib_massively_2017 after our additional QC steps.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "km_17.rds")
if (file.exists(rds)) {
  km_17 <- readRDS(rds)
} else {
  km_17 <- kmeans(
    reducedDim(sce, "PCA"), centers = 17, iter.max = 1e8, nstart = 2500, algorithm = "MacQueen")
  saveRDS(km_17, rds)}
```

```{r}
gg_df$km_17_clusters <- as.factor(km_17$cluster)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_17_clusters = levels(gg_df$km_17_clusters), label = levels(gg_df$km_17_clusters))
label_df2 <- gg_df %>%
  group_by(km_17_clusters) %>%
  summarize(svd_umap1 = median(svd_umap1), svd_umap2 = median(svd_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_umap1", y = "svd_umap2", col = "km_17_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("KM 17 Clusters SVD UMAP")
```

# IN Neurons of the PFC

We continue looking in the PFC region, this time looking specifically at inhibitory neurons which was shown so far to have several distinct subclusters.

## Cleaning and QC {.tabset}

Though QC was already performed on the imported datasets, we perform another round for greater fidelity.

### Habib 2017 snRNAseq

#### Subsetting

We start by subsetting to our areas of interest using the k-means clusters from the previous analysis.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce.rds"))

# Create a unique cache for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache2"))) {
  dir.create(file.path(assets_dir, "cache2"))}

regions <- "PFC"
c_types <- "GABA1|GABA2"
keep <- grepl(regions, colData(sce)$cell_id_stem)
sce <- sce[ , keep]
keep <- grepl(c_types, colData(sce)$km_18_clusters_name)
sce <- sce[ , keep]
dim(sce)
```

#### Low Quality Cells

In order to remove droplets which do not contain a cell but are rather ambient RNA, we visualize the inflection point on a knee plot, as described originally in @macosko_highly_2015.
Removal was then to be originally done using `emptyDrops` from the `DropletUtils` package, but due to an unresolved error (`no counts available to estimate the ambient profile`), we skip it.

```{r}
bc_rank <- barcodeRanks(counts(sce))
uniq <- !duplicated(bc_rank$rank)
par(mar = c(5, 4, 2, 1), bty = "n")
plot(
  bc_rank$rank[uniq], bc_rank$total[uniq], log = "xy", xlab = "Rank",
  ylab = "Total UMI Count", cex = 0.5, cex.lab = 1.2)
abline(h = metadata(bc_rank)$inflection, col = "darkgreen", lty = 2, lwd = 2)
abline(h = metadata(bc_rank)$knee, col = "dodgerblue", lty = 2, lwd = 2)
legend(
  "left", legend = c("Inflection", "Knee"), bty = "n", col = c("darkgreen", "dodgerblue"),
  lty = 2, cex = 1.2, lwd = 2)
```

```{r, cache = TRUE}
# Commented out due to "no counts available to estimate the ambient profile" error.
# rds <- file.path(assets_dir, "cache", "e_out.rds")
# if (file.exists(rds)) {
#   e_out <- readRDS(rds)
# } else {
#   set.seed(1)
#   e_out <- emptyDrops(counts(sce))
#   saveRDS(e_out, rds)}
```

#### Mito/Ribo Genes

Using an annotation from [HGNC](https://www.genenames.org/), we assess the proportion of mitochondrial/ribosomal genes within the cells.

```{r}
ribo_genes <- read.table(file.path(assets_dir, "ribo-genes.txt"), sep = "\t", header = TRUE)
is_mito <- which(rowData(sce)$chromosome_name == "MT")
is_ribo <- which(rowData(sce)$external_gene_name %in% ribo_genes$Approved.Symbol)
sce <- calculateQCMetrics(sce, feature_controls = list(Mt = is_mito, Ri = is_ribo))
par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
hist(
  log10(sce$total_counts), xlab = "log10(Library Sizes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Cells")
hist(
  log10(sce$total_features_by_counts), xlab = "log10(Number of Expressed Genes)", main = "",
  breaks = 20, col = "grey80", ylab = "Number of Cells")
hist(
  sce$pct_counts_Ri, xlab = "Ribosomal Proportion Percentage", ylab = "Number of Cells",
  breaks = 40, main = "", col = "grey80")
hist(
  sce$pct_counts_Mt, xlab = "Mitochondrial Proportion Percentage", ylab = "Number of Cells",
  breaks = 80, main = "", col = "grey80")
par(mfrow = c(2, 2), mar = c(5, 4, 1, 1), bty = "n")
smoothScatter(
  log10(sce$total_counts), log10(sce$total_features_by_counts),
  xlab = "log10(Library Sizes)", ylab = "log10(Num. Expressed Genes)")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_Ri,
  xlab = "log10(Library Sizes)", ylab = "Ribosomal Proportion %")
smoothScatter(
  log10(sce$total_counts), sce$pct_counts_Mt,
  xlab = "log10(Library Sizes)", ylab = "Mitochondrial Proportion %")
smoothScatter(
  sce$pct_counts_Ri,sce$pct_counts_Mt, xlab = "Ribosomal Proportion %",
  ylab = "Mitochondrial Proportion %")
```

We then use the `isOutlier` function from `scater` to remove cells with an overabundance of mitochondrial/ribosomal gene expression, as these are likely to be damaged cells.
We also remove cells determined to be low quality by their library size and feature counts.
In the table below, "TRUE" indicates cells that are kept.

```{r}
libsize_drop <- isOutlier(sce$total_counts, nmads = 3, type = "lower", log = TRUE)
feature_drop <- isOutlier(sce$total_features_by_counts, nmads = 3, type = "lower", log = TRUE)
mito_drop <- isOutlier(sce$pct_counts_Mt, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_Ri, nmads = 3, type = "higher")
keep <- !(libsize_drop | feature_drop | mito_drop | ribo_drop)
kable(table(colData(sce)$habib_cluster, keep), row.names = TRUE, padding = 0) %>%
  kable_styling(bootstrap_options = "striped", font_size = 13, full_width = FALSE, position = "left")
sce <- sce[ , keep]
dim(sce)
```

#### Lowly Expressed Genes

According to the original paper, nuclei that have less than 200 genes in one or more UMIs should be removed.
We start by first visualizing some gene-level summary statistics.

```{r}
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Cells + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Cells + 1)")
```

We remove genes as necessary and view the summary statistics again.

```{r}
names(rowData(sce))[names(rowData(sce)) == "strand"] <- "strand_n" # Must be renamed due to error.
n_genes <- colSums(counts(sce) >= 2)
n_genes <- colSums(counts(sce) >= 1)
n_cells <- rowSums(counts(sce) >= 2)
sce <- sce[which(n_cells >= 10), ]
dim(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Cells + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Cells + 1)")
```

#### Normalization

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell types/sizes [@l_lun_pooling_2016], producing "scale factor" values that indicates the extent to which a cell should be scaled.
For additional QC, we also remove cells that have size factors from the function that are very small ($< 0.01$) or negative.
In an experiment where most systematic differences between cells are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size, so we visualize this.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  quickCluster <- quickCluster(sce, use.ranks = FALSE, min.mean = 0.1, method = "igraph")
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce <- size_factors
sce <- sce[ , which(sizeFactors(sce) > 0.01)]
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are very well-correlated, which not only confirm the source of bias but also indicate that the previous QC steps were sufficient, therefore we go ahead and normalize the data.

```{r}
sce <- normalize(sce)
dim(sce)
```

## Dimensionality Reduction {.tabset}

This section details steps taken to reduce the dimensionality of the dataset.

### Habib 2017 snRNAseq

#### Habib tSNE Habib Clusters

We start by visualizing the tSNE coordinates provided in @habib_massively_2017 at this subset level.
Note that the subset was performed based on the k-means clusters from the previous analysis, so the clusters derived from @habib_massively_2017 will be expectedly more heterogeneous.

```{r}
# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    paste0("habib_tsne", 1:2), paste0("hvg_svd_tsne", 1:2),
    "habib_cluster_name", "km_18_clusters_name",
    "cell_id_stem", "log10_total_features_by_counts")])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
gg_df$km_18_clusters_name <- factor(gg_df$km_18_clusters_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons Habib Clusters Habib tSNE")
```

#### Whole Set HVG SVD tSNE HVG k-means

Next we take a look at both the k-means clusters and HVG SVD tSNEs created in the previous analysis.

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_18_clusters_name = levels(gg_df$km_18_clusters_name),
  label = levels(gg_df$km_18_clusters_name))
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(hvg_svd_tsne1 = median(hvg_svd_tsne1), hvg_svd_tsne2 = median(hvg_svd_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_svd_tsne1", y = "hvg_svd_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons KM 18 Clusters Whole Set HVG SVD tSNE")
```

#### PCA

Now generating new data, we perform PCA using `denoisePCA` from the `scran` package, which automatically selects PCs by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

```{r}
sce <- pca
add_df <- data.frame(reducedDim(sce, "PCA"))
names(add_df) <- paste0("denoise_sub_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_sub_pc1 = add_df$denoise_sub_pc1, denoise_sub_pc2 = add_df$denoise_sub_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])
```

We use the first 11 PCs, chosen by visually identifying the dropoff in variance explained.

```{r}
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = 11, lty = 2, col = "red")
```

We visualize only the first two components as they may have more descriptive power than usual for this smaller subset.

```{r}
plotPCA(sce, colour_by = "km_18_clusters_name") +
  ggtitle("PFC IN Neurons KM 18 Clusters denoisePCA") + theme(legend.title = element_blank())
```

As an alternative, we also use a truncated SVD (singular value decomposition) method to generate PCs. This approach was found to be less sensitive to the influence of batch effects.

```{r}
edat <- t(as.matrix(logcounts(sce)))
edat <- scale(edat)
```

We set the desired eigentriples to the number of components selected after inspecting the `denoisePCA` results.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  ppk <- propack.svd(edat, neig = 11)
  saveRDS(ppk, rds)}
```

```{r}
svd_pca <- t(ppk$d * t(ppk$u))
add_df <- data.frame(svd_pca)
names(add_df) <- paste0("svd_sub_pc", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_sub_pc1 = add_df$svd_sub_pc1, svd_sub_pc2 = add_df$svd_sub_pc2)
gg_df <- data.frame(gg_df, add_df[1:2])

dim_red_plot(
  data = gg_df, x = "svd_sub_pc1", y = "svd_sub_pc2", col = "km_18_clusters_name", type = "other") +
  xlab("PC1") + ylab("PC2") + ggtitle("PFC IN Neurons KM 18 Clusters SVD PCA")
```

#### tSNE

We first try using the first 11 PCs from the `denoisePCA` function.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "denoise_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  tsne <- runTSNE(sce, use_dimred = "PCA", n_dimred = 11, perplexity = 30, rand_seed = 1)
  saveRDS(tsne, rds)}
```

```{r}
sce <- tsne
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("denoise_sub_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_sub_tsne1 = add_df$denoise_sub_tsne1,
  denoise_sub_tsne2 = add_df$denoise_sub_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(
    denoise_sub_tsne1 = median(denoise_sub_tsne1), denoise_sub_tsne2 = median(denoise_sub_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_sub_tsne1", y = "denoise_sub_tsne2",
  col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons KM 18 denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "denoise_sub_tsne1", y = "denoise_sub_tsne2",
  col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") +
  ggtitle("PFC IN Neurons KM 18 Sample Distribution denoisePCA tSNE")
dim_red_plot(
  data = gg_df, x = "denoise_sub_tsne1", y = "denoise_sub_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") +
  ggtitle("PFC IN Neurons KM 18 log10(Total Features) denoisePCA tSNE")
```

Next using the SVD PCs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "svd_tsne.rds")
if (file.exists(rds)) {
  tsne <- readRDS(rds)
} else {
  set.seed(1)
  tsne <- Rtsne(svd_pca, pca = FALSE, perplexity = 30)
  saveRDS(tsne, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = svd_pca, TSNE = tsne$Y)
add_df <- data.frame(reducedDim(sce, "TSNE"))
names(add_df) <- paste0("svd_sub_tsne", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), svd_sub_tsne1 = add_df$svd_sub_tsne1, svd_sub_tsne2 = add_df$svd_sub_tsne2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(km_18_clusters_name) %>%
  summarize(svd_sub_tsne1 = median(svd_sub_tsne1), svd_sub_tsne2 = median(svd_sub_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2", col = "km_18_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons KM 18 SVD tSNE")
dim_red_plot(
  data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2",
  col = "cell_id_stem", type = "other") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons KM 18 Sample Distribution SVD tSNE")
dim_red_plot(
  data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons KM 18 log10(Total Features) SVD tSNE")
```

#### HVG

We now reduce dimensions using a new set of the top ~500 HVGs specific for our subset.
We start by plotting the variability of genes in our dataset against the expected Poisson technical noise.

```{r}
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))
par(mfrow = c(1, 1), mar = c(5, 4, 2, 1), bty = "n")
plot(
  fit$mean, fit$var, pch = 20,
  col = rgb(0.1, 0.2, 0.7, 0.6), xlab = "log(Mean)", ylab = "Variance")
curve(fit$trend(x), col = "orange", lwd = 2, add = TRUE)
curve(new_trend(x), col = "red", lwd = 2, add = TRUE)
legend(
  "top", legend = c("Poisson Noise", "Observed Trend"), lty = 1,
  lwd = 2, col = c("red", "orange"), bty = "n")
```

We extract the genes with the largest biological components and plot them here.

```{r}
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
top_dec <- dec[order(dec$bio, decreasing = TRUE), ]
plotExpression(sce, features = rownames(top_dec)[1:10])
```

For comparison, we also visualize the top 50 genes by total expression, not taking into account the components.

```{r}
plotHighestExprs(sce)
```

Finally, we select the top roughly 500 HVGs using their FDR and biological residual thresholds and visualize them below.

```{r}
dec1 <- dec
dec1$bio[which(dec$bio < 1e-1)] <- 1e-1
dec1$FDR[which(dec$FDR < 1e-100)] <- 1e-100
kable(table(dec$FDR < 1e-1, dec$bio > 1e-5), row.names = TRUE, padding = 0) %>%
  kable_styling(bootstrap_options = "striped", font_size = 13, full_width = FALSE, position = "left")
par(mfrow = c(1, 2))
hist(log10(dec1$bio), breaks = 100, main = "")
hist(log10(dec1$FDR), breaks = 100, main = "")
```

We see that our desired number of HVGs are only reached at a threshold of $FDR < 0.1$.
As this threshold is not stringent enough, we opt to use all genes for downstream analysis instead.

## Clustering {.tabset}

While the previous sections explored the components and visualizations of previously generated clusters, we create new ones here.

### Habib 2017 snRNAseq

#### SC3

Using SC3, we attempt a deeper clustering of the data, generating clusters in the range of 2-8.

```{r}
num_clust <- c(2:8)
rowData(sce)$feature_symbol <- rowData(sce)$external_gene_name
counts(sce) <- as.matrix(counts(sce))
logcounts(sce) <- as.matrix(logcounts(sce))
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache2", "sce.rds")
if (file.exists(rds)) {
  sce <- readRDS(rds)
} else {
  sce <- sc3(sce, ks = num_clust, biology = TRUE)
  saveRDS(sce, rds)}
```

```{r}
for (i in num_clust) {
  sc3_label <- paste0("sc3_", i, "_clusters")
  gg_df[[sc3_label]] <- as.factor(colData(sce)[ , sc3_label])}

clusts <- c(paste0("sc3_", num_clust, "_clusters"))
clusts_nice <- c(paste0("SC3 ", num_clust, " Clusters"))

for (i in 1:length(clusts)) {
  print(dim_red_plot(
    data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2", col = clusts[i], type = "other") +
      xlab("tSNE 1") + ylab("tSNE 2") +
      ggtitle(paste("PFC IN Neurons", clusts_nice[i], "SVD tSNE")))}
```

#### Labeling

Now we add labels to the set(s) we are interested.

**SC3 2 Clusters**

By looking at only two clusters, we mimic the clusters generated with SC3 when including excitatory cells as well as the 17 clusters using k-means from the previous analysis and the clusters in @habib_massively_2017.

```{r}
gg_df$sc3_2_clusters_name <- NA
sc3_2_clusters <- as.integer(gg_df$sc3_2_clusters)
for (i in 1:length(sc3_2_clusters)) {
  if (sc3_2_clusters[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "GABA1"
  } else if (sc3_2_clusters[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "GABA2"}}

colData(sce) <- cbind(colData(sce), sc3_2_clusters_name = gg_df$sc3_2_clusters_name)
gg_df$sc3_2_clusters_name <- factor(gg_df$sc3_2_clusters_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  sc3_2_clusters_name = levels(gg_df$sc3_2_clusters_name),
  label = levels(gg_df$sc3_2_clusters_name))
label_df2 <- gg_df %>%
  group_by(sc3_2_clusters_name) %>%
  summarize(svd_sub_tsne1 = median(svd_sub_tsne1), svd_sub_tsne2 = median(svd_sub_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2",
  col = "sc3_2_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons SC3 2 Clusters SVD tSNE")
```

**SC3 8 Clusters**

We also look at the largest cluster set generated.

```{r}
gg_df$sc3_8_clusters_name <- NA
sc3_8_clusters <- as.integer(gg_df$sc3_8_clusters)
for (i in 1:length(sc3_8_clusters)) {
  if (sc3_8_clusters[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "GABA1.1"
  } else if (sc3_8_clusters[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "GABA2.1.1"
  } else if (sc3_8_clusters[i] == 3) {
    gg_df[i, ncol(gg_df)] <- "GABA1.2"
  } else if (sc3_8_clusters[i] == 4) {
    gg_df[i, ncol(gg_df)] <- "GABA2.2.1"
  } else if (sc3_8_clusters[i] == 5) {
    gg_df[i, ncol(gg_df)] <- "GABA2.1.2"
  } else if (sc3_8_clusters[i] == 6) {
    gg_df[i, ncol(gg_df)] <- "GABA1.3"
  } else if (sc3_8_clusters[i] == 7) {
    gg_df[i, ncol(gg_df)] <- "GABA2.2.2"
  } else if (sc3_8_clusters[i] == 8) {
    gg_df[i, ncol(gg_df)] <- "GABA1.4"}}

colData(sce) <- cbind(colData(sce), sc3_8_clusters_name = gg_df$sc3_8_clusters_name)
gg_df$sc3_8_clusters_name <- factor(gg_df$sc3_8_clusters_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  sc3_8_clusters_name = levels(gg_df$sc3_8_clusters_name),
  label = levels(gg_df$sc3_8_clusters_name))
label_df2 <- gg_df %>%
  group_by(sc3_8_clusters_name) %>%
  summarize(svd_sub_tsne1 = median(svd_sub_tsne1), svd_sub_tsne2 = median(svd_sub_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "svd_sub_tsne1", y = "svd_sub_tsne2",
  col = "sc3_8_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("PFC IN Neurons SC3 8 Clusters SVD tSNE")
```

## Differential Expression {.tabset}

In this section, we calculate differentially expressed genes (DEGs) and identify marker genes for each cluster.
It should be noted that the top ~500 HVGs identified earlier are being used for this section, rather than the whole set of genes.

### Habib 2017 snRNAseq

```{r}
labeled_clusts <- c(2:8)
pdata <- c("sc3_2_clusters_name", "sc3_8_clusters_name")
```

#### Expression Matrix

First, we plot an expression matrix to get an overview of the overall expression of each cluster.

```{r}
for (i in labeled_clusts) {
  print(sc3_plot_expression(sce, k = i, show_pdata = pdata))}
```

#### DEG

Next, we calculate DEGs using a non-parametric Kruskal-Wallis test.
The figure displays the top 50 DEGs where $p < 0.01$.

```{r, fig.height = 9}
for (i in labeled_clusts) {
  print(sc3_plot_de_genes(sce, k = i, show_pdata = pdata))}
```

#### Marker Genes

To assign marker genes, a binary classifier is constructed based on the mean cluster expression value.
Classifier prediction is then calculated using the gene expression ranks.
Genes with $AUROC > 0.1$ and $p < 0.01$ are selected and the top 10 are visualized in the following figure.

```{r, fig.height = 11.5}
for (i in labeled_clusts) {
  print(sc3_plot_markers(sce, k = i, auroc = 0.1, show_pdata = pdata))}
```

We can also view a data table containing all the marker genes.

```{r}
markers <- as.data.frame(organise_marker_genes(sce, k = 2, p_val = 0.01, auroc = 0.1))
markers$sc3_2_clusters_name <- NA
sc3_2_clusters <- as.integer(markers$sc3_2_markers_clusts)
for (i in 1:length(sc3_2_clusters)) {
  if (sc3_2_clusters[i] == 1) {
    markers[i, ncol(markers)] <- "GABA1"
  } else if (sc3_2_clusters[i] == 2) {
    markers[i, ncol(markers)] <- "GABA2"}}
datatable(as.data.table(markers))

markers <- as.data.frame(organise_marker_genes(sce, k = 8, p_val = 0.01, auroc = 0.1))
markers$sc3_8_clusters_name <- NA
sc3_8_clusters <- as.integer(markers$sc3_8_markers_clusts)
for (i in 1:length(sc3_8_clusters)) {
  if (sc3_8_clusters[i] == 1) {
    markers[i, ncol(markers)] <- "GABA1.1"
  } else if (sc3_8_clusters[i] == 2) {
    markers[i, ncol(markers)] <- "GABA2.1.1"
  } else if (sc3_8_clusters[i] == 3) {
    markers[i, ncol(markers)] <- "GABA1.2"
  } else if (sc3_8_clusters[i] == 4) {
    markers[i, ncol(markers)] <- "GABA2.2.1"
  } else if (sc3_8_clusters[i] == 5) {
    markers[i, ncol(markers)] <- "GABA2.1.2"
  } else if (sc3_8_clusters[i] == 6) {
    markers[i, ncol(markers)] <- "GABA1.3"
  } else if (sc3_8_clusters[i] == 7) {
    markers[i, ncol(markers)] <- "GABA2.2.2"
  } else if (sc3_8_clusters[i] == 8) {
    markers[i, ncol(markers)] <- "GABA1.4"}}
datatable(as.data.table(markers))
```

# References

This is the concluding section of the document.
Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
sessionInfo()
```
