---
title: "Tau Vulnerability Report"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    number_sections: true
    theme: lumen
    highlight: zenburn
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/tau-vulnerability-report.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7, error = TRUE)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This is an in-depth analysis to characterize differential vulnerability to tauopathy.*

The background for this data is as follows:

This analysis was performed in R except where noted.
The source code and instructions for rerunning the analysis can be found at [github.com/eturkes/tau-vulnerability](https://github.com/eturkes/tau-vulnerability).

# Final Results

**Read just this section for the final results of the analysis and a summary of the methods.**

# ~~~ Breakdown of Methods ~~~ {-}

The following top-level sections break down the methods used to perform the analysis and only needs to be read if one is interested.
We start by loading in any required packages and setting some global variables.

```{r}
packages <- c(
  "conflicted", "ggplot2", "SingleCellExperiment", "data.table", "DT", "scran", "scater",
  "BiocSingular", "svd", "Rtsne", "S4Vectors", "SC3", "gprofiler2")
invisible(suppressMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

dim_red_plot <- function(data, x, y, col, type) {
	gg <- ggplot(data, aes_string(x = x, y = y)) +
		geom_point(size = 0.2, alpha = 0.6, aes_string(col = col)) +
	  theme_classic() + theme(legend.position = "bottom")
	if (type == "cont") {
		gg <- gg + scale_colour_gradient(low = "blue", high = "red")
	} else if (type == "cat") {
		gg <- gg + guides(color = guide_legend(override.aes = list(size = 3)))
	}
	gg}

name_change <- function(data, orig_name, new_name) {
	index = which(names(data) == orig_name)
	if (length(index) > 0) {
		names(data)[index] = new_name
	}
	data}

# Taken from SC3.
organise_marker_genes <- function(object, k, p_val, auroc) {
  dat <- rowData(object)[ , c(
    paste0("sc3_", k, "_markers_clusts"), paste0("sc3_", k, "_markers_auroc"),
    paste0("sc3_", k, "_markers_padj"), "feature_symbol")]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_padj")] < p_val & !is.na(
    dat[, paste0("sc3_", k, "_markers_padj")]), ]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_auroc")] > auroc, ]
  d <- NULL
  for (i in sort(unique(dat[, paste0("sc3_", k, "_markers_clusts")]))) {
    tmp <- dat[dat[, paste0("sc3_", k, "_markers_clusts")] == i, ]
    tmp <- tmp[order(tmp[, paste0("sc3_", k, "_markers_auroc")], decreasing = TRUE), ]
    d <- rbind(d, tmp)}
  if (nrow(dat) > 0) {
    return(d)
  } else {
    return(NULL)}}
```

# Original Data

We start by reading in data from previous broad analyses and displaying their final results.

## Habib 2017 snRNAseq {.tabset}

The cleaned dataset here is derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq) *(currently private, please email for access)* which uses data from @habib_massively_2017.
For full details of preprocessing, please see that analysis, but in brief, standard QC for droplet-based UMI protocols was applied with attention to particular thresholds used in @habib_massively_2017.
The main results of the original publication is k-nearest-neighbor clustering visualized by tSNE, which identified 15 cell types within PFC and hippocampal tissues of five healthy human donors.
As cluster labels and tSNE coordinates were released by the authors, the main figure was recreated in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq), along with a successful attempt at replicating that data.

```{r}
habib_2017_all_clust <- readRDS(file.path(assets_dir, "habib_2017_all_clust.rds"))
# TODO: Fix issue with cluster 15 being missing.
```

### Orig. Clusters Orig. tSNE

The original clusters and tSNE coordinates.

```{r}
dim_red_plot(
  data = habib_2017_all_clust, x = "habib_tsne1", y = "habib_tsne2",
  col = "habib_cluster", type = "cat")
```

### Orig. Clusters New tSNE

The original clusters with new tSNE coordinates based on HVGs (highly variable genes).

```{r}
dim_red_plot(
  data = habib_2017_all_clust, x = "hvg_tsne1", y = "hvg_tsne2",
  col = "habib_cluster", type = "cat")
```

### New Clusters Orig. tSNE

New clusters generated by k-means atop the first 50 PCs (principal components) with the original tSNE coordinates.

```{r}
dim_red_plot(
  data = habib_2017_all_clust, x = "habib_tsne1", y = "habib_tsne2",
  col = "km_14_clusters", type = "cat")
```

### New Clusters New tSNE

The new clusters and tSNE coordinates.

```{r}
dim_red_plot(
  data = habib_2017_all_clust, x = "hvg_tsne1", y = "hvg_tsne2",
  col = "km_14_clusters", type = "cat")
```

# Ex/In Neurons of the PFC

We start by looking in the PFC region and performing deeper clustering on both excitatory and inhibitory neurons.

```{r}
rm(habib_2017_all_clust)

# Create a unique cache for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache1"))) {
  dir.create(file.path(assets_dir, "cache1"))}

regions <- "PFC"
cell_types <- "exPFC1|exPFC2|GABA1|GABA2"

habib_2017_sce <- readRDS(file.path(assets_dir, "habib_2017_sce.rds"))
keep <- grepl(regions, colData(habib_2017_sce)$cell_id_stem)
habib_2017_sce <- habib_2017_sce[, keep]
keep <- grepl(cell_types, colData(habib_2017_sce)$habib_cluster_name)
habib_2017_sce <- habib_2017_sce[, keep]
```

## Dimensionality Reduction {.tabset}

We use several approaches to identify clusters and each tab presents a particular method.

### PCA

```{r}
new_trend <- makeTechTrend(x = habib_2017_sce)
fit <- trendVar(habib_2017_sce, use.spikes = FALSE, loess.args = list(span = 0.05))
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
rm(fit)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "habib_2017_pca.rds")
if (file.exists(rds)) {
  habib_2017_pca <- readRDS(rds)
} else {
  habib_2017_pca <- denoisePCA(habib_2017_sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(habib_2017_pca, rds)}
```

```{r}
habib_2017_sce <- habib_2017_pca
rm(habib_2017_pca)
df_redDim <- data.frame(
  colData(habib_2017_sce)[ , c(
    "sample", "cell_id_stem", paste0("habib_tsne", 1:2), "log10_total_features_by_counts",
    "habib_cluster", "habib_cluster_name", "habib_cell_type")],
  reducedDim(habib_2017_sce, "PCA")[ , 1:2],
  stringsAsFactors = FALSE)
rownames(df_redDim) <- NULL

plotPCA(habib_2017_sce, colour_by = "log10_total_features_by_counts")
```

### Habib tSNE

As tSNE coordinates were released with the original dataset, we plot them here to replicate the results of @habib_massively_2017.

```{r}
dim_red_plot(
  data = df_redDim, x = "habib_tsne1", y = "habib_tsne2", col = "habib_cluster_name", type = "cat")
dim_red_plot(
  data = df_redDim, x = "habib_tsne1", y = "habib_tsne2", col = "cell_id_stem", type = "cat")
dim_red_plot(
  data = df_redDim, x = "habib_tsne1", y = "habib_tsne2",
  col = "log10_total_features_by_counts", type = "cont")
dim_red_plot(
  data = df_redDim, x = "habib_tsne1", y = "habib_tsne2", col = "habib_cell_type", type = "cat")
```

### All Genes tSNE

We also calculate and plot new tSNE coordinates using all of the genes in the subsetted dataset.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "habib_2017_runTSNE.rds")
if (file.exists(rds)) {
  habib_2017_runTSNE <- readRDS(rds)
} else {
  habib_2017_runTSNE <- runTSNE(habib_2017_sce, use_dimred = "PCA", perplexity = 30, rand_seed = 100)
  saveRDS(habib_2017_runTSNE, rds)}
```

```{r}
habib_2017_sce <- habib_2017_runTSNE
tmp_df <- data.frame(reducedDim(habib_2017_sce, "TSNE"), stringsAsFactors = FALSE)
rownames(tmp_df) <- NULL
names(tmp_df) <- paste0("new_tsne", 1:2)
df_redDim <- data.frame(df_redDim, tmp_df, stringsAsFactors = FALSE)

dim_red_plot(
  data = df_redDim, x = "new_tsne1", y = "new_tsne2", col = "habib_cluster_name", type = "cat")
dim_red_plot(
  data = df_redDim, x = "new_tsne1", y = "new_tsne2", col = "cell_id_stem", type = "cat")
dim_red_plot(
  data = df_redDim, x = "new_tsne1", y = "new_tsne2",
  col = "log10_total_features_by_counts", type = "cont")
dim_red_plot(
  data = df_redDim, x = "new_tsne1", y = "new_tsne2", col = "habib_cell_type", type = "cat")
rm(df_redDim, tmp_df, habib_2017_runTSNE)
```

### HVG tSNE

We now cluster using the top 1,000 HVGs.

```{r}
# Select the top 1,000 HVGs.
dec1 <- dec
dec1$bio[which(dec$bio < 1e-5)] <- 1e-5
dec1$FDR[which(dec$FDR < 1e-100)] <- 1e-100
w2kp <- which(dec$FDR < 1e-10 & dec$bio > 0.02)
rm(dec, dec1)
habib_2017_sce_hvg <- habib_2017_sce[w2kp, ]
edat <- t(as.matrix(logcounts(habib_2017_sce_hvg)))
edat <- scale(edat)
```

```{r, cache = TRUE}
# Perform PCA.
rds <- file.path(assets_dir, "cache1", "habib_2017_ppk.rds")
if (file.exists(rds)) {
  habib_2017_ppk <- readRDS(rds)
} else {
  habib_2017_ppk <- propack.svd(edat, neig = 50)
  saveRDS(habib_2017_ppk, rds)}
```

```{r}
pca <- t(habib_2017_ppk$d*t(habib_2017_ppk$u))
rm(edat, habib_2017_ppk)
tmp_df <- data.frame(pca[ , 1:2], stringsAsFactors = FALSE)
names(tmp_df) <- paste0("hvg_pc", seq(ncol(tmp_df)))
habib_2017_df_hvg <- data.frame(
  colData(habib_2017_sce)[ , c(
    "sample", "cell_id_stem", paste0("habib_tsne", 1:2), "log10_total_features_by_counts",
    "habib_cluster", "habib_cluster_name", "habib_cell_type"
  )],
  tmp_df,
  stringsAsFactors = FALSE)
rownames(habib_2017_df_hvg) <- NULL
```

```{r, cache = TRUE}
# Perform tSNE.
rds <- file.path(assets_dir, "cache1", "habib_2017_Rtsne.rds")
if (file.exists(rds)) {
  habib_2017_Rtsne <- readRDS(rds)
} else {
  set.seed(100)
  habib_2017_Rtsne <- Rtsne(pca, pca = FALSE, perplexity = 30)
  saveRDS(habib_2017_Rtsne, rds)}
```

```{r}
tmp_df <- data.frame(habib_2017_Rtsne$Y, stringsAsFactors = FALSE)
names(tmp_df) <- paste0("hvg_tsne", seq(ncol(tmp_df)))
habib_2017_df_hvg <- data.frame(habib_2017_df_hvg, tmp_df, stringsAsFactors = FALSE)
reducedDims(habib_2017_sce_hvg) <- SimpleList(PCA = pca, TSNE = habib_2017_Rtsne$Y)
rm(habib_2017_Rtsne, pca, tmp_df)

dim_red_plot(
  data = habib_2017_df_hvg, x = "hvg_tsne1", y = "hvg_tsne2",
  col = "habib_cluster_name", type = "cat")
dim_red_plot(
  data = habib_2017_df_hvg, x = "hvg_tsne1", y = "hvg_tsne2", col = "cell_id_stem", type = "cat")
dim_red_plot(
  data = habib_2017_df_hvg, x = "hvg_tsne1", y = "hvg_tsne2",
  col = "log10_total_features_by_counts", type = "cont")
dim_red_plot(
  data = habib_2017_df_hvg, x = "hvg_tsne1", y = "hvg_tsne2", col = "habib_cell_type", type = "cat")
```

## Clustering

### k-means

We apply a k-means method atop the 50 PCs generated earlier, choosing to generate 2-4 clusters.

```{r}
all_num_clust <- c(2:4)
habib_2017_df_hvg <- habib_2017_df_hvg[ , !grepl("^KM_", names(habib_2017_df_hvg))]
rowData(habib_2017_sce_hvg)$feature_symbol <- rowData(habib_2017_sce_hvg)$external_gene_name
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "habib_2017_km_label.rds")
if (file.exists(rds)) {
  km_label <- readRDS(rds)
  habib_2017_df_hvg <- readRDS(file.path(assets_dir, "cache1", "habib_2017_df_hvg1.rds"))
} else {
  for (num_clust in all_num_clust) {
    cat(paste0("k-means with ", num_clust, " clusters.\n"))
    kmeans_out <- kmeans(
      reducedDim(habib_2017_sce_hvg, "PCA"), centers = num_clust, iter.max = 1e8,
      nstart = 2500, algorithm = "MacQueen")
    habib_2017_km_label <- paste0("km_", num_clust, "_clusters")
    habib_2017_df_hvg[[habib_2017_km_label]] = as.factor(kmeans_out$cluster)
    rm(kmeans_out)}
  saveRDS(habib_2017_km_label, rds)
  saveRDS(habib_2017_df_hvg, file.path(assets_dir, "cache1", "habib_2017_df_hvg1.rds"))}
```

### SC3

As an alternative method, we generate another set of 2-4 clusters using SC3.

```{r}
rowData(habib_2017_sce)$feature_symbol <- rowData(habib_2017_sce)$external_gene_name
counts(habib_2017_sce) <- as.matrix(counts(habib_2017_sce))
logcounts(habib_2017_sce) <- as.matrix(logcounts(habib_2017_sce))
all_ks <- c(2:4)
p_data <- c("habib_cluster_name", "cell_id_stem")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache1", "habib_2017_df_hvg2.rds")
if (file.exists(rds)) {
  habib_2017_df_hvg <- readRDS(rds)
  habib_2017_sce <- readRDS(file.path(assets_dir, "cache1", "habib_2017_sce.rds"))
} else {
  habib_2017_sce <- sc3(habib_2017_sce, ks = all_ks, biology = TRUE)
  for (one_ks in all_ks) {
    sc3_label <- paste0("sc3_", one_ks, "_clusters")
    habib_2017_df_hvg[[sc3_label]] <- as.factor(colData(habib_2017_sce)[, sc3_label])}
  saveRDS(habib_2017_df_hvg, rds)
  saveRDS(habib_2017_sce, file.path(assets_dir, "cache1", "habib_2017_sce.rds"))}
```

## Cluster Mapping {.tabset}

Now we visualize the correlation between our new cluster set as well as the original clusters in @habib_massively_2017.
We start by reading in Supplementary Table 7 (nmeth.4407-S10.xlsx) from @habib_massively_2017 to provide a consistent set of labels and merging it into our data.

```{r}
# Read in supplemental information.
tmp_lab <- read.table(
  file.path(assets_dir, "cluster-num-label.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
tmp_lab <- name_change(tmp_lab, "Name", "habib_cluster_name")
tmp_lab <- name_change(tmp_lab, "Name.1", "habib_cell_type")
tmp_lab <- name_change(tmp_lab, "Cell.ID", "sample")
tmp_lab <- name_change(tmp_lab, "Cell.Type.ID", "habib_cluster")

tmp_clust <- read.table(
  file.path(assets_dir, "paper-cluster.txt"), sep = "\t", header = TRUE,
  comment.char = "", stringsAsFactors = FALSE)
tmp_clust <- name_change(tmp_clust, "X.Genes", "n_genes")
tmp_clust <- name_change(tmp_clust, "X.Transcripts", "n_transcripts")
tmp_clust <- name_change(tmp_clust, "Cell.ID", "sample")
tmp_clust <- name_change(tmp_clust, "Cluster.ID", "habib_cluster")
tmp_clust <- name_change(tmp_clust, "Cluster.Name", "habib_cluster_name")

tmp_clust <- merge(
  tmp_clust,
  tmp_lab[ , c("habib_cluster_name", "habib_cell_type")],
  by = intersect(names(tmp_clust), names(tmp_lab[ , c("habib_cluster_name", "habib_cell_type")])),
  all.x = TRUE)

# Merge into our data.
habib_2017_all_clust <- merge(
  habib_2017_df_hvg, tmp_clust, by = intersect(names(habib_2017_df_hvg), names(tmp_clust)))

sc3_clust <- data.frame(
  colData(habib_2017_sce)[ , paste0("sc3_", all_ks, "_clusters")], stringsAsFactors = FALSE)
for (ks in all_ks) {
  sc3_label <- paste0("sc3_", ks, "_clusters")
  sc3_clust[ , sc3_label] <- as.factor(sc3_clust[ , sc3_label])}
sc3_clust$sample <- colnames(habib_2017_sce)

habib_2017_all_clust <- merge(
  habib_2017_all_clust, sc3_clust, by = intersect(names(habib_2017_all_clust), names(sc3_clust)))
rm(habib_2017_df_hvg, tmp_clust, tmp_lab, sc3_clust)
```

We visualize our clusters using tSNE, looking at both the HVG tSNE generated earlier and coloring our clustering results atop of the clusters in @habib_massively_2017.

```{r}
all_vars <- c(
  "habib_cluster_name", "habib_cell_type",
  paste0("km_", all_ks, "_clusters"), paste0("sc3_", all_ks, "_clusters"))
```

### HVG tSNE

```{r}
for (var in all_vars) {
  print(dim_red_plot(
    data = habib_2017_all_clust, x = "hvg_tsne1", y = "hvg_tsne2", col = var, type = "cat"))}
```

### Habib tSNE

```{r}
for (var in all_vars) {
  print(dim_red_plot(
    data = habib_2017_all_clust, x = "habib_tsne1", y = "habib_tsne2", col = var, type = "cat"))}
```

### Consensus Matrix

We can also assess the performance of our SC3 clusters using a correlation matrix.
In an ideal situation, diagonal blocks will be completely red while off-diagonal elements are completely blue.

```{r, cache = TRUE}
# Commented out due to memory demands.
# for (k in all_ks) {
#   sc3_plot_consensus(habib_2017_sce, k = k, show_pdata = p_data)}
```

The diagonality of the concensus matrix can be quantitatively measured using a silhouette plot, where 1 represents a perfectly block-diagonal consensus matrix.

```{r}
# Commented out for now due to errors.
# for (k in all_ks) {
#   sc3_plot_silhouette(habib_2017_sce, k = k)}
```

## Differential Expression

In this section, we calculate differentially expressed genes (DEGs) between the newly created clusters, eventually using this data to assign marker genes to each cluster.

### Expression Matrix

Though this figure does not describe DEGs, it is the first step of a DEG analysis.
The heatplot describes the absolute expression of each gene across the clusters.

```{r, cache = TRUE}
for (k in all_ks) {
  sc3_plot_expression(habib_2017_sce, k = k, show_pdata = p_data)}
```

### Kruskal-Wallis

Our chosen method to calculate DEGs will be the non-parametric Kruskal-Wallis test.
The figure displays the top 50 DEGs where $p < 0.01$.

```{r, fig.height = 9}
for (k in all_ks) {
  sc3_plot_de_genes(habib_2017_sce, k = k, show_pdata = p_data)}
```

### Marker Genes

To assign marker genes, a binary classifier is constructed based on the mean cluster expression value.
Classifier prediction is then calculated using the gene expression ranks.
Genes with $AUROC > 0.6$ and $p < 0.01$ are selected and the top 10 are visualized in the following figure.

```{r, fig.height = 7}
markers <- as.data.frame(organise_marker_genes(habib_2017_sce, k = 4, p_val = 0.01, auroc = 0.6))
for (k in all_ks) {
  sc3_plot_markers(habib_2017_sce, k = k, show_pdata = p_data, p.val = 0.01, auroc = 0.6)}
```

## Pathway Analysis

We take marker genes or other interesting DE genes and perform pathway analysis to find enriched pathways.

### g:Profiler

```{r}
gprofiler_sources <- c("GO", "KEGG", "REAC")
```

### Cluster 1

```{r}
keep <- which(markers$sc3_4_markers_clusts == 1)
clust_markers <- markers[keep, ]
gprofiler_out <- gost(
  rownames(clust_markers), organism = "hsapiens", ordered_query = TRUE, sources = gprofiler_sources)
gostplot(gprofiler_out)
```

```{r, fig.width = 11, fig.height = 25}
publish_gosttable(gprofiler_out)
```

### Cluster 2

```{r}
keep <- which(markers$sc3_4_markers_clusts == 2)
clust_markers <- markers[keep, ]
gprofiler_out <- gost(
  rownames(clust_markers), organism = "hsapiens", ordered_query = TRUE, sources = gprofiler_sources)
gostplot(gprofiler_out)
```

```{r, fig.width = 11, fig.height = 25}
publish_gosttable(gprofiler_out)
```

### Cluster 3

```{r}
keep <- which(markers$sc3_4_markers_clusts == 3)
clust_markers <- markers[keep, ]
gprofiler_out <- gost(
  rownames(clust_markers), organism = "hsapiens", ordered_query = TRUE, sources = gprofiler_sources)
gostplot(gprofiler_out)
```

```{r, fig.width = 11, fig.height = 25}
publish_gosttable(gprofiler_out)
```

### Cluster 4

```{r}
keep <- which(markers$sc3_4_markers_clusts == 4)
clust_markers <- markers[keep, ]
gprofiler_out <- gost(
  rownames(clust_markers), organism = "hsapiens", ordered_query = TRUE, sources = gprofiler_sources)
gostplot(gprofiler_out)
```

```{r, fig.width = 11, fig.height = 25}
publish_gosttable(gprofiler_out)
rm(gprofiler_out)
```

# References

This is the concluding section of the document.
Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
sessionInfo()
```
