---
title: "21 Habib Neuronal GSEA"
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding,
      output_file = "../results/21-habib-neuronal-gsea.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 15, fig.height = 13)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

This document follows up its preparation file to provide and in-depth analysis of neuronal populations in the dataset from @habib_massively_2017.
We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd", "SC3",
  "DT", "data.table", "Seurat", "uwot", "viridis", "pheatmap", "RColorBrewer", "GSVA", "GSEABase",
  "limma")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "21"))) {
  dir.create(file.path(assets_dir, "cache", "21"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "21"))) {
  dir.create(file.path(results_dir, "data", "21"), recursive = TRUE)}

# Adds download buttons.
datatable_custom <- function(dt) {
  datatable(
    dt,
    extensions = "Buttons", options = list(dom = "Blfrtip", buttons = list(
      "copy", "print",
      list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download"))))}
```

Prep the data.

```{r}
sce_hvg <- readRDS(file.path(results_dir, "data", "13", "sce_hvg.rds"))
seurat_hvg <- readRDS(file.path(results_dir, "data", "13", "seurat_hvg.rds"))
sce_orig <- readRDS(file.path(results_dir, "data", "08", "sce_orig.rds"))
seurat_orig <- as.Seurat(sce_orig)

keep <- readRDS(file.path(results_dir, "data", "08", "keep1.rds"))
sce_orig <- sce_orig[ , keep]
seurat_orig <- seurat_orig[ , keep]
keep <- readRDS(file.path(results_dir, "data", "08", "keep2.rds"))
sce_orig <- sce_orig[ , keep]
sce_orig <- calculateQCMetrics(sce_orig)
seurat_orig <- seurat_orig[ , keep]
seurat_orig <- NormalizeData(seurat_orig)
seurat_orig <- ScaleData(seurat_orig, features = rownames(seurat_orig))
keep <- readRDS(file.path(results_dir, "data", "13", "keep1.rds"))
sce_orig <- sce_orig[ , keep]
seurat_orig <- seurat_orig[ , keep]

umap <- as.matrix(data.frame(sce_hvg$IN_hvg_ppk_umap1, sce_hvg$IN_hvg_ppk_umap2))
colnames(umap) <- paste0("UMAP_", 1:2)
rownames(umap) <- colnames(sce_orig)
seurat_orig[["UMAP"]] <- CreateDimReducObject(
  embeddings = umap, key = "UMAP_", assay = DefaultAssay(seurat_orig))
Idents(object = seurat_orig) <- Idents(object = seurat_hvg)
IN_seurat <- seurat_orig
IN_seurat

sce_hvg <- readRDS(file.path(results_dir, "data", "12", "sce_hvg.rds"))
seurat_hvg <- readRDS(file.path(results_dir, "data", "12", "seurat_hvg.rds"))
sce_orig <- readRDS(file.path(results_dir, "data", "08", "sce_orig.rds"))
seurat_orig <- as.Seurat(sce_orig)

keep <- readRDS(file.path(results_dir, "data", "08", "keep1.rds"))
sce_orig <- sce_orig[ , keep]
seurat_orig <- seurat_orig[ , keep]
keep <- readRDS(file.path(results_dir, "data", "08", "keep2.rds"))
sce_orig <- sce_orig[ , keep]
sce_orig <- calculateQCMetrics(sce_orig)
seurat_orig <- seurat_orig[ , keep]
seurat_orig <- NormalizeData(seurat_orig)
seurat_orig <- ScaleData(seurat_orig, features = rownames(seurat_orig))
keep <- readRDS(file.path(results_dir, "data", "12", "keep1.rds"))
sce_orig <- sce_orig[ , keep]
seurat_orig <- seurat_orig[ , keep]

umap <- as.matrix(data.frame(sce_hvg$EX_hvg_ppk_umap1, sce_hvg$EX_hvg_ppk_umap2))
colnames(umap) <- paste0("UMAP_", 1:2)
rownames(umap) <- colnames(sce_orig)
seurat_orig[["UMAP"]] <- CreateDimReducObject(
  embeddings = umap, key = "UMAP_", assay = DefaultAssay(seurat_orig))
Idents(object = seurat_orig) <- Idents(object = seurat_hvg)
EX_seurat <- seurat_orig
rm(sce_hvg, sce_orig, seurat_hvg, seurat_orig)
EX_seurat
```

# GSEA Prep

## IN

```{r}
PVALB_seurat <- subset(x = IN_seurat, idents = "0")
PVALB_mat <- as.matrix(GetAssayData(object = PVALB_seurat, slot = "scale.data"))
dim(PVALB_mat)
CALB2_seurat <- subset(x = IN_seurat, idents = "1")
CALB2_mat <- as.matrix(GetAssayData(object = CALB2_seurat, slot = "scale.data"))
dim(CALB2_mat)
SST_seurat <- subset(x = IN_seurat, idents = "2")
SST_mat <- as.matrix(GetAssayData(object = SST_seurat, slot = "scale.data"))
dim(SST_mat)
comb_mat <- cbind(PVALB_mat, CALB2_mat, SST_mat)
rowsums <- data.table(rowSums(comb_mat) / dim(comb_mat)[2])
names(rowsums) <- "rank"
rowsums <- data.table(GeneSets = rownames(comb_mat), rowsums)
write.table(
  rowsums, file = file.path(assets_dir, "gsea", "21", "IN", "IN.rnk"), sep = "\t",
  quote = FALSE, row.names = FALSE)
```

## EX

```{r}
TBR1_SATB2_seurat <- subset(x = EX_seurat, idents = "2")
TBR1_SATB2_mat <- as.matrix(GetAssayData(object = TBR1_SATB2_seurat, slot = "scale.data"))
dim(TBR1_SATB2_mat)
comb_mat <- TBR1_SATB2_mat
rowsums <- data.table(rowSums(comb_mat) / dim(comb_mat)[2])
names(rowsums) <- "rank"
rowsums <- data.table(GeneSets = rownames(comb_mat), rowsums)
write.table(
  rowsums, file = file.path(assets_dir, "gsea", "21", "EX", "EX.rnk"), sep = "\t",
  quote = FALSE, row.names = FALSE)
```

# References

This is the concluding section of the document. Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
sessionInfo()
```
