---
title: "11 Habib Neuronal Pathway Analysis"
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/11-habib-neuronal-pathways.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 15, fig.height = 13)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

This document follows up its preparation file to provide and in-depth analysis of neuronal populations in the dataset from @habib_massively_2017.
We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd", "SC3",
  "DT", "data.table", "Seurat", "uwot", "viridis", "WGCNA", "pheatmap", "RColorBrewer", "GSVA",
  "GSEABase")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "11"))) {
  dir.create(file.path(assets_dir, "cache", "11"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "11"))) {
  dir.create(file.path(results_dir, "data", "11"), recursive = TRUE)}

# Adds download buttons.
datatable_custom <- function(dt) {
  datatable(
    dt,
    extensions = "Buttons", options = list(dom = "Blfrtip", buttons = list(
      "copy", "print",
      list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download"))))}
```

We load in the data from the previous analysis.

```{r}
seurat_hvg <- readRDS(file.path(assets_dir, "cache", "08", "seurat_hvg_res.rds"))

sce_hvg <- readRDS(file.path(results_dir, "data", "08", "sce_hvg.rds"))

sce_orig <- readRDS(file.path(results_dir, "data", "08", "sce_orig.rds"))
keep <- readRDS(file.path(results_dir, "data", "08", "keep1.rds"))
sce_orig <- sce_orig[ , keep]
keep <- readRDS(file.path(results_dir, "data", "08", "keep2.rds"))
sce_orig <- sce_orig[ , keep]
sce_orig <- calculateQCMetrics(sce_orig)
detected_genes <- rowSums(counts(sce_orig) >= 1)
sce_orig <- sce_orig[which(detected_genes >= 1), ]

seurat_orig <- as.Seurat(sce_orig, counts = "counts", data = NULL)
umap <- as.matrix(data.frame(sce_hvg$sub_hvg_ppk_umap1, sce_hvg$sub_hvg_ppk_umap2))
colnames(umap) <- paste0("UMAP_", 1:2)
rownames(umap) <- colnames(sce_orig)
seurat_orig[["UMAP"]] <- CreateDimReducObject(
  embeddings = umap, key = "UMAP_", assay = DefaultAssay(seurat_orig))
Idents(object = seurat_orig) <- Idents(object = seurat_hvg)
seurat_orig <- NormalizeData(seurat_orig)
seurat_orig <- ScaleData(seurat_orig, features = rownames(seurat_orig))

rm(seurat_hvg, sce_hvg, sce_orig, umap)
seurat_orig
```

# GSVA

```{r}
gene_sets <- getGmt(file.path(assets_dir, "gsva", "11", "c5.bp.v7.0.symbols.gmt"))
```

```{r}
genes <- c("TBR1", "SATB2", "SST", "CALB2")

# for (i in 1:length(genes)) {
#   keep <- FetchData(object = seurat_hvg, vars = genes[i])
#   sub_seurat <- seurat_hvg[ , which(x = keep > 0)]
#   genes_mat <- GetAssayData(object = sub_seurat, slot = "scale.data")}

genes_mat <- matrix(data = 0, nrow = dim(seurat_orig)[1], ncol = length(genes))
rownames(genes_mat) <- rownames(seurat_orig)
colnames(genes_mat) <- genes
for (i in 1:length(genes)) {
  keep <- FetchData(object = seurat_orig, vars = genes[i], slot = "counts")
  sub_seurat <- seurat_orig[ , which(x = keep > 0)]
  genes_mat[ , i] <- rowSums(
    GetAssayData(object = sub_seurat, slot = "counts")) / dim(seurat_orig)[2]}
rm(keep)
datatable_custom(head(genes_mat))
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "11", "gsva.rds")
if (file.exists(rds)) {
  gsva <- readRDS(rds)
} else {
  gsva <- gsva(genes_mat, gene_sets, kcdf = "Poisson")
  saveRDS(gsva, rds)}
```

```{r}
gene_sets[["GO_CYTIDINE_TO_URIDINE_EDITING"]]@geneIds
genes_mat[grepl("APOE*", rownames(genes_mat)), ]
```
