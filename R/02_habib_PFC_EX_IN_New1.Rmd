---
title: "02 Habib PFC EX/IN New1"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/02-habib-PFC-EX-IN-New1.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
.tocify-subheader .tocify-subheader .tocify-item {
  font-size: 0.90em; padding-left: 35px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd",
  "SC3", "DT", "data.table", "Seurat", "uwot", "viridis")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "02"))) {
  dir.create(file.path(assets_dir, "cache", "02"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "03"))) {
  dir.create(file.path(results_dir, "data", "03"), recursive = TRUE)}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_viridis()}
  gg}

# From SC3 source, needed to look at more marker genes than the top 10.
organise_marker_genes <- function(object, k, p_val, auroc) {
  dat <- rowData(object)[ , c(
    paste0("sc3_", k, "_markers_clusts"), paste0("sc3_", k, "_markers_auroc"),
    paste0("sc3_", k, "_markers_padj"), "feature_symbol")]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_padj")] < p_val & !is.na(
    dat[, paste0("sc3_", k, "_markers_padj")]), ]
  dat <- dat[dat[ , paste0("sc3_", k, "_markers_auroc")] > auroc, ]
  d <- NULL
  for (i in sort(unique(dat[, paste0("sc3_", k, "_markers_clusts")]))) {
    tmp <- dat[dat[, paste0("sc3_", k, "_markers_clusts")] == i, ]
    tmp <- tmp[order(tmp[, paste0("sc3_", k, "_markers_auroc")], decreasing = TRUE), ]
    d <- rbind(d, tmp)}
  if (nrow(dat) > 0) {
    return(d)
  } else {
    return(NULL)}}

# Adds download buttons.
datatable_custom <- function(dt) {
  datatable(
    dt,
    extensions = "Buttons", options = list(dom = "Blfrtip", buttons = list(
      "copy", "print",
      list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download"))))}
```

We use the SCE object created in `01_habib_2017_snRNAseq_prep.Rmd` and subset it to our areas of interest.

```{r}
sce <- readRDS(file.path(results_dir, "data", "01", "sce.rds"))
regions <- "PFC"
c_types <- "exPFC|GABA|New1"
keep <- grepl(regions, colData(sce)$cell_id_stem)
sce <- sce[ , keep]
keep <- grepl(c_types, colData(sce)$seurat_clusters_name)
sce <- sce[ , keep]
sce
```

# QC

## Lowly Expressed Genes

We remove genes that are now lowly expressed after the subset.

```{r}
sce <- calculateQCMetrics(sce)
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

## Normalization

Due to the change in dimensions from subsetting, we renormalize.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce <- normalize(sce)
rm(size_factors)
```

# Dimensionality Reduction

## PPK SVD + UMAP

We use the PROPACK SVD + UMAP combination used in `01_habib_2017_snRNAseq_prep.Rmd`.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
retain_pcs <- 19
retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = retain_pcs, lty = 2, col = "red")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(pca[ , 1:retain_pcs], min_dist = 0.2)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("sub_ppk_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), sub_ppk_umap1 = add_df$sub_ppk_umap1, sub_ppk_umap2 = add_df$sub_ppk_umap2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", "log10_total_features_by_counts", "seurat_clusters_name")], add_df)
rownames(gg_df) <- NULL
gg_df$seurat_clusters_name <- factor(gg_df$seurat_clusters_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(sub_ppk_umap1 = median(sub_ppk_umap1), sub_ppk_umap2 = median(sub_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2",
  col = "seurat_clusters_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Whole Set Seurat Clusters Subset PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution Subset PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) PPK UMAP")
```

## HVG

```{r}
new_trend <- makeTechTrend(x = sce)
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
top_dec <- rownames(dec[order(dec$bio, decreasing = TRUE), ])[1:10]
rm(fit)
plotExpression(sce, features = top_dec) +
  stat_summary(
    fun.y = median, fun.ymin = median, fun.ymax = median, geom = "crossbar", width = 0.3, alpha = 0.8)

fdr_median <- median(dec$FDR, na.rm = TRUE)
fdr_median
bio_median <- median(dec$bio, na.rm = TRUE)
bio_median
```

We decide that the FDR median is too large to be used as a cutoff, so we use half of the median, which is more reasonable.

```{r, fig.height = 6}
fdr_half_median <- median(dec$FDR, na.rm = TRUE) / 2
fdr_half_median
bio_half_median <- median(dec$bio, na.rm = TRUE) / 2
bio_half_median

par(mfrow = c(1, 2))
hist(log10(dec$FDR), breaks = 100, main = "")
abline(v = c(log10(fdr_half_median), log10(min(dec$FDR[dec$FDR > 0]))), lty = 2, col = "red")
hist(log10(dec$bio), breaks = 100, main = "")
abline(v = c(log10(bio_half_median), log10(max(dec$bio))), lty = 2, col = "red")

keep <- which(dec$FDR < fdr_half_median & dec$bio >= bio_half_median)
sce_hvg <- sce[keep, ]
rm(dec)
dim(sce_hvg)[1]
```

We retain ~2,000 HVGs, a suitable number for our analysis.

### PPK SVD + UMAP

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "hvg_ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce_hvg)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
hvg_retain_pcs <- 21
hvg_retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = hvg_retain_pcs, lty = 2, col = "red")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "hvg_ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(pca[ , 1:hvg_retain_pcs], min_dist = 0.2)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce_hvg) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce_hvg, "UMAP"))
names(add_df) <- paste0("sub_hvg_ppk_umap", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), sub_hvg_ppk_umap1 = add_df$sub_hvg_ppk_umap1,
  sub_hvg_ppk_umap2 = add_df$sub_hvg_ppk_umap2)
colData(sce) <- cbind(
  colData(sce), sub_hvg_ppk_umap1 = add_df$sub_hvg_ppk_umap1,
  sub_hvg_ppk_umap2 = add_df$sub_hvg_ppk_umap2)
gg_df <- data.frame(gg_df, add_df)
rm(pca, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "seurat_clusters_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Whole Set Seurat Clusters Subset HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution Subset HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) Subset HVG PPK UMAP")
```

We see that subsetting to HVGs clarifies the UMAP figure, so we use those coordinates for all downstream analysis.

# Clustering

We compute new clusters using the new `sce_hvg` as testing found it to produce significantly cleaner clusters than with all genes.



We also note that the minimum clusters produced are 5.
It would also be useful to examine 2 clusters on this particular subset, therefore, we lower the `resolution` to value where these are produced.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "seurat_hvg0.1.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = 0.1)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters0.1 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters0.1 = levels(gg_df$hvg_seurat_clusters0.1),
  label = levels(gg_df$hvg_seurat_clusters0.1))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters0.1) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters0.1", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat 0.1 Resolution Clusters Subset HVG PPK UMAP")
```

## SC3

As an alternative, we try clustering using SC3.
First, we estimate the optimal $k$ for our dataset.

```{r}
rowData(sce_hvg)$feature_symbol = rowData(sce_hvg)$external_gene_name
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "02", "hvg_sc3_estimate_k.rds")
if (file.exists(rds)) {
  hvg_sc3_estimate_k <- readRDS(rds)
} else {
  set.seed(1)
  hvg_sc3_estimate_k <- sc3_estimate_k(sce_hvg)
  saveRDS(hvg_sc3_estimate_k, rds)}
```

```{r}
sce_hvg <- hvg_sc3_estimate_k
rm(hvg_sc3_estimate_k)
metadata(sce_hvg)$sc3$k_estimation
```

While SC3's optimal $k$ seems large compared to Seurat's suggestions, as it is computationally feasible, we stick with it and generate 2-20 clusters to provide a margin of error.

