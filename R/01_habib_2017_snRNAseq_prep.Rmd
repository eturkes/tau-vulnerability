---
title: "01 Habib 2017 snRNAseq Prep"
author:
  - name: "Emir Turkes [et2628@cumc.columbia.edu]"
  - name: "Columbia University"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/01-habib-2017-snRNAseq-prep.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

In this document we apply additional processing on the cleaned dataset derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq), which uses droplet-based UMI data from @habib_massively_2017.
We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd",
  "SC3", "DT", "data.table", "Seurat", "uwot", "viridis")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "01"))) {
  dir.create(file.path(assets_dir, "cache", "01"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "01"))) {
  dir.create(file.path(results_dir, "data", "01"), recursive = TRUE)}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_viridis()}
  gg}
```

# Original Data

As cluster labels and tSNE coordinates were released by the authors, Figure 2a and 2b were recreated in the analysis, along with their successful replication in addition to Figure 2d.
Please see the analysis for details of the processing, which was performed in close accordance to what was done in @habib_massively_2017.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce.rds"))
sce

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    paste0("habib_tsne", 1:2), paste0("hvg_tsne", 1:2),
    "habib_cluster_name", "seurat_hvg_clusters_name")])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)
gg_df$seurat_hvg_clusters_name <- factor(gg_df$seurat_hvg_clusters_name)
```

### Habib Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters Habib tSNE")
```

### HVG Seurat Clusters Habib tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_hvg_clusters_name = levels(gg_df$seurat_hvg_clusters_name),
  label = levels(gg_df$seurat_hvg_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_hvg_clusters_name) %>%
  summarize(habib_tsne1 = median(habib_tsne1), habib_tsne2 = median(habib_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "habib_tsne1", y = "habib_tsne2",
  col = "seurat_hvg_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("HVG Seurat Clusters Habib tSNE")
```

### HVG Seurat Clusters HVG tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_hvg_clusters_name = levels(gg_df$seurat_hvg_clusters_name),
  label = levels(gg_df$seurat_hvg_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_hvg_clusters_name) %>%
  summarize(hvg_tsne1 = median(hvg_tsne1), hvg_tsne2 = median(hvg_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_tsne1", y = "hvg_tsne2", col = "seurat_hvg_clusters_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("HVG Seurat Clusters HVG tSNE")
```

### Habib Clusters HVG tSNE

```{r}
# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name), label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_tsne1 = median(hvg_tsne1), hvg_tsne2 = median(hvg_tsne2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_tsne1", y = "hvg_tsne2", col = "habib_cluster_name", type = "cat") +
  xlab("tSNE 1") + ylab("tSNE 2") + ggtitle("Habib Clusters HVG tSNE")
```

# QC

We switch to a version of the dataset that has not had data removed from the original in order to make a new attempt at QC.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce_orig.rds"))
sce
```

## Low Quality Nuclei

We remove nuclei overabundant in mitochondrial/ribosomal gene expression, a common indicator of low quality nuclei.

```{r}
mito_drop <- isOutlier(sce$pct_counts_mito, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_ribo, nmads = 3, type = "higher")
keep <- !(mito_drop | ribo_drop)
datatable(data.table(
  "By Mitochondrial" = sum(mito_drop), "By Ribosomal" = sum(ribo_drop),
  Remaining = sum(keep)))
sce <- sce[ , keep]
dim(sce)[2]
```

## Lowly Expressed Genes

We consider the expression profile of genes each time nuclei are removed.
A distinctly negative skew can be seen due to lowly expressed genes in our dataset.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

Therefore, we remove genes in the manner specified in @habib_massively_2017.

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it.
For each analysis, genes were removed that were detected in less than 10 nuclei.

```{r}
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

We see a robust improvement in normality.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

We then display some additional summary statistics.
Apparent is the disproportionately high expression of encoding lncRNAs MALAT1 and MEG3, both of which are known to have higher expression in nuclei, as noted in @habib_massively_2017.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
plotExprsFreqVsMean(sce)
```

## Normalization

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell types/sizes, producing "size factor" values that indicate the extent to which nuclei should be scaled.
We also perform a rough clustering of our nuclei, which improves accuracy on highly heterogenous data such as that from the brain.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

In an experiment where most systematic differences between nuclei are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size.

```{r}
sce <- size_factors
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are well correlated, confirming the source of bias.
We therefore add normalized expression data to our SCE object using the calculated size factors.

```{r}
sce <- normalize(sce)
sce
```

# Dimensionality Reduction

## Technical Summation + UMAP

We start by applying `denoisePCA` from the `scran` package, which can automatically select the number of PCs to retain by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  set.seed(1)
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

The results suggest retaining the following number of PCs:

```{r}
sce <- pca
ncol(reducedDim(sce, "PCA"))
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = ncol(reducedDim(sce, "PCA")), lty = 2, col = "red")
```

We assess the effectiveness of these PCs by using them to compute UMAP coordinates.

```{r}
rds <- file.path(assets_dir, "cache", "01", "denoise_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- runUMAP(sce, min_dist = 0.5)
  saveRDS(umap, rds)}
```

```{r}
sce <- umap
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("denoise_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_umap1 = add_df$denoise_umap1, denoise_umap2 = add_df$denoise_umap2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster_name")],
  add_df)
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_umap1 = median(denoise_umap1), denoise_umap2 = median(denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) denoisePCA UMAP")
```

## PPK SVD + UMAP

As an alternative, we can also calculate a truncated SVD (singular value decomposition) from which PCs can be extracted from it.
In our testing, this approach, particularly the PROPACK implementation, was found to have high power in distinguishing subpopulations of common cell types.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
retain_pcs <- 20
retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = retain_pcs, lty = 2, col = "red")
```

```{r}
rds <- file.path(assets_dir, "cache", "01", "ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(pca[ , 1:retain_pcs], min_dist = 0.5)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("ppk_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), ppk_umap1 = add_df$ppk_umap1, ppk_umap2 = add_df$ppk_umap2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters PPK UMAP")
dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution PPK UMAP")
dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) PPK UMAP")
```

## HVG

We subset to the most highly variable genes (HVGs) to reduce noise in our dataset.
As we do not have spike-in transcripts, we start by modeling the technical noise as Poisson and creating a fitted trend on that basis.

```{r}
new_trend <- makeTechTrend(x = sce)
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))
par(mfrow = c(1, 1), mar = c(5, 4, 2, 1), bty = "n")
plot(
  fit$mean, fit$var, pch = 20,
  col = rgb(0.1, 0.2, 0.7, 0.6), xlab = "Mean Log-expression", ylab = "Variance")
curve(fit$trend(x), col = "orange", lwd = 2, add = TRUE)
curve(new_trend(x), col = "red", lwd = 2, add = TRUE)
legend(
  "top", legend = c("Poisson Noise", "Observed Trend"), lty = 1,
  lwd = 2, col = c("red", "orange"), bty = "n")
```

The plot shows a large discrepancy between the two trends, which we assume is contributed by each gene's biological component.
We extract the genes with the largest biological components and plot them here.

```{r}
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
top_dec <- rownames(dec[order(dec$bio, decreasing = TRUE), ])[1:10]
rm(fit)
plotExpression(sce, features = top_dec) +
  stat_summary(
    fun.y = median, fun.ymin = median, fun.ymax = median, geom = "crossbar", width = 0.3, alpha = 0.8)
```

We inspect the distribution of our FDR and biological component values to see how see should proceed.

```{r, fig.height = 6}
fdr_median <- median(dec$FDR, na.rm = TRUE)
fdr_median
bio_median <- median(dec$bio, na.rm = TRUE)
bio_median

par(mfrow = c(1, 2))
hist(log10(dec$FDR), breaks = 100, main = "")
abline(v = c(log10(fdr_median), log10(min(dec$FDR[dec$FDR > 0]))), lty = 2, col = "red")
hist(log10(dec$bio), breaks = 100, main = "")
abline(v = c(log10(bio_median), log10(max(dec$bio))), lty = 2, col = "red")
```

We see that thresholding at the median is able to capture most of the desired distribution of both values.
Let's see what number of genes we would subset to with these thresholds.

```{r}
keep <- which(dec$FDR < fdr_median & dec$bio >= bio_median)
sce_hvg <- sce[keep, ]
rm(dec)
dim(sce_hvg)[1]
```

This approach captures identifies about 5,000 HVGs, a suitable number for downstream analysis.
Due to the change in dimensions, we renormalize and calculate new QC metrics.

```{r}
sce_hvg <- calculateQCMetrics(sce_hvg)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "hvg_quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce_hvg, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "hvg_size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce_hvg, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce_hvg <- size_factors
sce_hvg <- normalize(sce_hvg)
rm(size_factors)
sce_hvg
```

### PPK SVD + UMAP

We now test the effectiveness of our HVGs through the PPK SVD + UMAP method described earlier.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "hvg_ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce_hvg)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
hvg_retain_pcs <- 18
hvg_retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = hvg_retain_pcs, lty = 2, col = "red")
```

```{r}
rds <- file.path(assets_dir, "cache", "01", "hvg_ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(pca[ , 1:hvg_retain_pcs], min_dist = 0.5)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce_hvg) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce_hvg, "UMAP"))
names(add_df) <- paste0("hvg_ppk_umap", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), hvg_ppk_umap1 = add_df$hvg_ppk_umap1, hvg_ppk_umap2 = add_df$hvg_ppk_umap2)
colData(sce) <- cbind(
  colData(sce), hvg_ppk_umap1 = add_df$hvg_ppk_umap1, hvg_ppk_umap2 = add_df$hvg_ppk_umap2)
gg_df <- data.frame(gg_df, add_df)
rm(pca, umap, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(hvg_ppk_umap1 = median(hvg_ppk_umap1), hvg_ppk_umap2 = median(hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) HVG PPK UMAP")
```

# Clustering

## SC3

Due computational demands of SC3, we do not run it on the full dataset.
However, we do use the `sc3_estimate_k` to predict an optimal $k$ for other clustering algorithms.

```{r}
rowData(sce)$feature_symbol = rowData(sce)$external_gene_name
rowData(sce_hvg)$feature_symbol = rowData(sce_hvg)$external_gene_name
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "sc3_estimate_k.rds")
if (file.exists(rds)) {
  sc3_estimate_k <- readRDS(rds)
} else {
  set.seed(1)
  sc3_estimate_k <- sc3_estimate_k(sce)
  saveRDS(sc3_estimate_k, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "hvg_sc3_estimate_k.rds")
if (file.exists(rds)) {
  hvg_sc3_estimate_k <- readRDS(rds)
} else {
  set.seed(1)
  hvg_sc3_estimate_k <- sc3_estimate_k(sce_hvg)
  saveRDS(hvg_sc3_estimate_k, rds)}
```

```{r}
sce <- sc3_estimate_k
rm(sc3_estimate_k)
metadata(sce)$sc3$k_estimation

sce_hvg <- hvg_sc3_estimate_k
rm(hvg_sc3_estimate_k)
metadata(sce_hvg)$sc3$k_estimation
```

Unfortunately, we see that SC3 was not able to provide a reasonable estimation of $k$.
Therefore, we rely on other means to decide the optimal number of clusters to obtain.

## Seurat

Seurat is a nearest neighbor graph clustering method with a `resolution` parameter that indirectly influences the number of clusters generated.
Concerning `resolution`, the authors write:

> setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells.
Optimal resolution often increases for larger datasets.

As a compromise, we try simply scaling the median of these recommended settings (0.8, which is also the default) to the size of our dataset.

```{r}
resolution <- (dim(sce)[2] / 3000) * 0.8
resolution
```

We experiment with feature and PCA input derived from both all genes and HVGs.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "seurat.rds")
if (file.exists(rds)) {
  seurat <- readRDS(rds)
} else {
  seurat <- as.Seurat(sce, counts = "counts", data = NULL)
  seurat <- NormalizeData(seurat)
  seurat <- FindVariableFeatures(seurat, nfeatures = dim(sce)[1])
  seurat <- ScaleData(seurat, features = rownames(seurat))
  seurat <- FindNeighbors(seurat, reduction = "PCA", dims = 1:retain_pcs)
  seurat <- FindClusters(seurat, resolution = resolution)
  saveRDS(seurat, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "seurat_hvg.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$seurat_clusters <- seurat$seurat_clusters
gg_df$seurat_hvg_clusters <- seurat_hvg$seurat_clusters
rm(seurat_hvg)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters = levels(gg_df$seurat_clusters), label = levels(gg_df$seurat_clusters))
label_df2 <- gg_df %>%
  group_by(seurat_clusters) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "seurat_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Seurat Clusters PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_hvg_clusters = levels(gg_df$seurat_hvg_clusters), label = levels(gg_df$seurat_hvg_clusters))
label_df2 <- gg_df %>%
  group_by(seurat_hvg_clusters) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "seurat_hvg_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("HVG Seurat Clusters PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters = levels(gg_df$seurat_clusters), label = levels(gg_df$seurat_clusters))
label_df2 <- gg_df %>%
  group_by(seurat_clusters) %>%
  summarize(hvg_ppk_umap1 = median(hvg_ppk_umap1), hvg_ppk_umap2 = median(hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2", col = "seurat_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Seurat Clusters HVG PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_hvg_clusters = levels(gg_df$seurat_hvg_clusters), label = levels(gg_df$seurat_hvg_clusters))
label_df2 <- gg_df %>%
  group_by(seurat_hvg_clusters) %>%
  summarize(hvg_ppk_umap1 = median(hvg_ppk_umap1), hvg_ppk_umap2 = median(hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2", col = "seurat_hvg_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("HVG Seurat Clusters HVG PPK UMAP")
```

We see that Seurat produced 35 clusters with both datasets.
While they are similar, differences can be seen particularly regarding cells that lie between major clusters.

## k-means

To validate the Seurat clusters, we also try k-means on both datasets with $k$ set to 35.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "km_35.rds")
if (file.exists(rds)) {
  km_35 <- readRDS(rds)
} else {
  km_35 <- kmeans(
    reducedDim(sce, "PCA")[ , 1:retain_pcs], centers = 35, iter.max = 1e8,
    nstart = 2500, algorithm = "MacQueen")
  saveRDS(km_35, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "hvg_km_35.rds")
if (file.exists(rds)) {
  hvg_km_35 <- readRDS(rds)
} else {
  hvg_km_35 <- kmeans(
    reducedDim(sce_hvg, "PCA")[ , 1:hvg_retain_pcs], centers = 35, iter.max = 1e8,
    nstart = 2500, algorithm = "MacQueen")
  saveRDS(hvg_km_35, rds)}
```

```{r}
gg_df$km_35_clusters <- factor(km_35$cluster)
gg_df$hvg_km_35_clusters <- factor(hvg_km_35$cluster)
rm(km_35, hvg_km_35)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_35_clusters = levels(gg_df$km_35_clusters), label = levels(gg_df$km_35_clusters))
label_df2 <- gg_df %>%
  group_by(km_35_clusters) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "km_35_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("KM 35 Clusters PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_km_35_clusters = levels(gg_df$hvg_km_35_clusters), label = levels(gg_df$hvg_km_35_clusters))
label_df2 <- gg_df %>%
  group_by(hvg_km_35_clusters) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "hvg_km_35_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("HVG KM 35 Clusters PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  km_35_clusters = levels(gg_df$km_35_clusters), label = levels(gg_df$km_35_clusters))
label_df2 <- gg_df %>%
  group_by(km_35_clusters) %>%
  summarize(hvg_ppk_umap1 = median(hvg_ppk_umap1), hvg_ppk_umap2 = median(hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2",
  col = "km_35_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("KM 35 Clusters HVG PPK UMAP")

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_km_35_clusters = levels(gg_df$hvg_km_35_clusters), label = levels(gg_df$hvg_km_35_clusters))
label_df2 <- gg_df %>%
  group_by(hvg_km_35_clusters) %>%
  summarize(hvg_ppk_umap1 = median(hvg_ppk_umap1), hvg_ppk_umap2 = median(hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "hvg_ppk_umap1", y = "hvg_ppk_umap2", col = "hvg_km_35_clusters", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("HVG KM 35 Clusters HVG PPK UMAP")
```

## Labeling

After visually inspecting all of the cluster/UMAP combinations, we select the Seurat clusters using all genes overlaid onto the all genes PPK UMAP as being most suitable for our needs.
We go ahead and label these clusters based on their proximity to clusters from @habib_massively_2017 and their UMAP coordinates.

```{r}
gg_df$seurat_clusters_name <- NA
seurat_clusters <- as.integer(gg_df$seurat_clusters)
for (i in 1:length(seurat_clusters)) {
  if (seurat_clusters[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "exPFC1.1"
  } else if (seurat_clusters[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "ODC3"
  } else if (seurat_clusters[i] == 3) {
    gg_df[i, ncol(gg_df)] <- "ASC3"
  } else if (seurat_clusters[i] == 4) {
    gg_df[i, ncol(gg_df)] <- "exDG2"
  } else if (seurat_clusters[i] == 5) {
    gg_df[i, ncol(gg_df)] <- "exPFC1.3"
  } else if (seurat_clusters[i] == 6) {
    gg_df[i, ncol(gg_df)] <- "exCA3"
  } else if (seurat_clusters[i] == 7) {
    gg_df[i, ncol(gg_df)] <- "ODC1.2"
  } else if (seurat_clusters[i] == 8) {
    gg_df[i, ncol(gg_df)] <- "exPFC2.2"
  } else if (seurat_clusters[i] == 9) {
    gg_df[i, ncol(gg_df)] <- "GABA2.1"
  } else if (seurat_clusters[i] == 10) {
    gg_df[i, ncol(gg_df)] <- "exDG1"
  } else if (seurat_clusters[i] == 11) {
    gg_df[i, ncol(gg_df)] <- "ODC1.1"
  } else if (seurat_clusters[i] == 12) {
    gg_df[i, ncol(gg_df)] <- "exPFC2.1"
  } else if (seurat_clusters[i] == 13) {
    gg_df[i, ncol(gg_df)] <- "GABA1.1"
  } else if (seurat_clusters[i] == 14) {
    gg_df[i, ncol(gg_df)] <- "ASC2"
  } else if (seurat_clusters[i] == 15) {
    gg_df[i, ncol(gg_df)] <- "ODC2"
  } else if (seurat_clusters[i] == 16) {
    gg_df[i, ncol(gg_df)] <- "GABA1.2"
  } else if (seurat_clusters[i] == 17) {
    gg_df[i, ncol(gg_df)] <- "exDG3"
  } else if (seurat_clusters[i] == 18) {
    gg_df[i, ncol(gg_df)] <- "exCA1"
  } else if (seurat_clusters[i] == 19) {
    gg_df[i, ncol(gg_df)] <- "ASC1"
  } else if (seurat_clusters[i] == 20) {
    gg_df[i, ncol(gg_df)] <- "OPC2"
  } else if (seurat_clusters[i] == 21) {
    gg_df[i, ncol(gg_df)] <- "exPFC1.2"
  } else if (seurat_clusters[i] == 22) {
    gg_df[i, ncol(gg_df)] <- "OPC1"
  } else if (seurat_clusters[i] == 23) {
    gg_df[i, ncol(gg_df)] <- "exPFC1.5"
  } else if (seurat_clusters[i] == 24) {
    gg_df[i, ncol(gg_df)] <- "GABA2.2"
  } else if (seurat_clusters[i] == 25) {
    gg_df[i, ncol(gg_df)] <- "New4"
  } else if (seurat_clusters[i] == 26) {
    gg_df[i, ncol(gg_df)] <- "ODC1.3"
  } else if (seurat_clusters[i] == 27) {
    gg_df[i, ncol(gg_df)] <- "MG"
  } else if (seurat_clusters[i] == 28) {
    gg_df[i, ncol(gg_df)] <- "New2"
  } else if (seurat_clusters[i] == 29) {
    gg_df[i, ncol(gg_df)] <- "NSC"
  } else if (seurat_clusters[i] == 30) {
    gg_df[i, ncol(gg_df)] <- "exPFC1.4"
  } else if (seurat_clusters[i] == 31) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled3"
  } else if (seurat_clusters[i] == 32) {
    gg_df[i, ncol(gg_df)] <- "END"
  } else if (seurat_clusters[i] == 33) {
    gg_df[i, ncol(gg_df)] <- "New3"
  } else if (seurat_clusters[i] == 34) {
    gg_df[i, ncol(gg_df)] <- "Unlabeled1"
  } else if (seurat_clusters[i] == 35) {
    gg_df[i, ncol(gg_df)] <- "New1"}}

colData(sce_hvg) <- cbind(
  colData(sce_hvg), seurat_clusters = gg_df$seurat_clusters,
  seurat_clusters_name = gg_df$seurat_clusters_name)
colData(sce) <- cbind(
  colData(sce), seurat_clusters = gg_df$seurat_clusters,
  seurat_clusters_name = gg_df$seurat_clusters_name)
gg_df$seurat_clusters_name <- factor(gg_df$seurat_clusters_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  seurat_clusters_name = levels(gg_df$seurat_clusters_name),
  label = levels(gg_df$seurat_clusters_name))
label_df2 <- gg_df %>%
  group_by(seurat_clusters_name) %>%
  summarize(ppk_umap1 = median(ppk_umap1), ppk_umap2 = median(ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "ppk_umap1", y = "ppk_umap2", col = "seurat_clusters_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Seurat Clusters PPK UMAP")
```

We find that the final figure segregates the clusters nicely and is in good agreement with @habib_massively_2017.

# Differential Expresssion

We find upregulated genes in cell types formed by combining subclusters.

```{r}
seurat_clusters_id <- c(
  "exPFC", "ODC", "ASC", "exDG", "exPFC", "exCA", "ODC", "exPFC", "GABA", "exDG", "ODC", "exPFC",
  "GABA", "ASC", "ODC", "GABA", "exDG", "exCA", "ASC", "OPC", "exPFC", "OPC", "exPFC", "GABA",
  "NA", "ODC", "MG", "NA", "NSC", "exPFC", "NA", "END", "NA", "NA", "NA")
names(seurat_clusters_id) <- levels(seurat)
seurat <- RenameIdents(seurat, seurat_clusters_id)
rm(gg_df, label_df, label_df2)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "01", "seurat_markers.rds")
if (file.exists(rds)) {
  seurat_markers <- readRDS(rds)
} else {
  seurat_markers <- FindAllMarkers(seurat, only.pos = TRUE)
  saveRDS(seurat_markers, rds)}
```

```{r}
top <- seurat_markers %>% group_by(cluster) %>% top_n(n = 5, wt = avg_logFC)
DoHeatmap(seurat, features = top$gene, size = 1.5) +
  NoLegend() + scale_fill_gradientn(colors = c("blue", "white", "red"))
```

## IHC Genes

Next, we examine the expression of a set genes for which we have antibodies to conduct immunohistochemistry.

```{r}
genes <- c(
  "GRIA1", "GRIA2", "SATB1", "SATB2", "CALB1", "CALB2",
  "GAD1", "GAD2", "WFS1", "PVALB", "SST", "TBR1")
VlnPlot(seurat, features = genes[1:4], sort = TRUE, ncol = 2)
VlnPlot(seurat, features = genes[5:8], sort = TRUE, ncol = 2)
VlnPlot(seurat, features = genes[9:12], sort = TRUE, ncol = 2)
FeaturePlot(
  seurat, reduction = "UMAP", features = genes[1:4], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
FeaturePlot(
  seurat, reduction = "UMAP", features = genes[5:8], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
FeaturePlot(
  seurat, reduction = "UMAP", features = genes[9:12], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
DotPlot(seurat, features = genes, cols = c("blue", "red")) + RotatedAxis()
```

Several genes are present in lower quantities than expected.
The make sure this is not a processing error, we check them using minimal processing and the tSNE from @habib_massively_2017.

```{r}
sce_orig <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce_orig.rds"))
seurat_orig <- as.Seurat(sce_orig, counts = "counts", data = NULL)
habib_tsne <- as.matrix(data.frame(sce_orig$habib_tsne1, sce_orig$habib_tsne2))
colnames(habib_tsne) <- paste0("HabibTSNE_", 1:2)
rownames(habib_tsne) <- colnames(sce_orig)
seurat_orig[["habib_tsne"]] <- CreateDimReducObject(
  embeddings = habib_tsne, key = "HabibTSNE_", assay = DefaultAssay(seurat_orig))
seurat_orig <- NormalizeData(seurat_orig)
seurat_orig <- ScaleData(seurat_orig, features = rownames(seurat_orig))

FeaturePlot(
  seurat_orig, reduction = "habib_tsne", features = genes[1:4], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
FeaturePlot(
  seurat_orig, reduction = "habib_tsne", features = genes[5:8], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
FeaturePlot(
  seurat_orig, reduction = "habib_tsne", features = genes[9:12], order = TRUE,
  cols = c("lightgrey", "red"), max.cutoff = 20, ncol = 2)
DotPlot(seurat_orig, features = genes, cols = c("blue", "red")) + RotatedAxis()
```

It can be seen that despite differences in scaling, the minimally processed data shows similar characteristics as the analyzed set.

# References

This is the concluding section of the document. Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
saveRDS(sce, file.path(results_dir, "data", "01", "sce.rds"))
saveRDS(sce_hvg, file.path(results_dir, "data", "01", "sce_hvg.rds"))
saveRDS(seurat, file.path(results_dir, "data", "01", "seurat.rds"))
saveRDS(seurat_markers, file.path(results_dir, "data", "01", "seurat_markers.rds"))

sessionInfo()
```
