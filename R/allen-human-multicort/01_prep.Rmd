---
title: '01 Prep - `r unlist(strsplit(getwd(), "/"))[6]`'
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: '../../`r unlist(strsplit(getwd(), "/"))[4]`.bib'
link-citations: true
output:
  html_document:
    code_folding: hide
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(
    "..", "..", "results", unlist(strsplit(getwd(), "/"))[6], "01-prep.html"
  ))})
---

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

In this document we prepare the gene count matrix for downstream analysis.
The data here is derived from @`r unlist(strsplit(getwd(), "/"))[6]` and will be referenced using the name ``r unlist(strsplit(getwd(), "/"))[6]``.

```{r, boilerplate}
# Load in necessary boilerplate and libraries.
# --------------------------------------------

#    This file is part of tau-vulnerability.
#    Copyright (C) 2019-2020  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

# These should be checked per document.
# -------------------------------------

packages <- c(
  "conflicted", "BiocFileCache", "scrattch.io", "SingleCellExperiment", "scater",
  "DT", "data.table", "DropletUtils", "Seurat", "future",
  "biomaRt", "dplyr", "ggplot2", "ggrepel", "viridis"
)
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))
source(file.path(getwd(), "..", "utils.R"))

analysis_no <- 1
organism <- "human"
protocol_type <- c("smart-seq", "single-nuc") # 1st term = technology, 2nd term = sc or snRNAseq.
control_metadata <- NULL # 1st term = label, 2nd term = column.
batch_metadata <- "external_donor_name_label"
metadata_to_plot <- c(
  "seurat_clusters", "class_label", "region_label", "cluster_label", batch_metadata, "Phase"
)
no_legend <- c(1, 4)
no_label <- c(3, 5, 6)
vars_to_regress <- batch_metadata
parallel_override <- NULL # See function `parallel_plan` in `utils.R`.
download_name <- "transcrip.tome" # Name of download file corresponding to dataset.
options(stringsAsFactors = FALSE)
knitr::opts_chunk$set(fig.width = 10, fig.height = 10)

# Everything else in this chunk remains generally unchanged.
# ----------------------------------------------------------

data_name <- unlist(strsplit(getwd(), "/"))[6] # Name of dataset.
assets_dir <- file.path(getwd(), "..", "..", "assets", data_name) # Backed up caches and data.
tmp_dir <- file.path(getwd(), "..", "..", "tmp", data_name)
results_dir <- file.path(getwd(), "..", "..", "results", data_name)

if (!dir.exists(tmp_dir)) {
  dir.create(tmp_dir, recursive = TRUE)
}

# Unique cache directory for each analysis number.
if (!dir.exists(file.path(assets_dir, "cache", paste0("0", analysis_no)))) {
  dir.create(file.path(assets_dir, "cache", paste0("0", analysis_no)), recursive = TRUE)
}
```

# Cleaning

We start by gathering together the data and forming a SingleCellExperiment (SCE) object.

```{r, cleaning}
# This section typically needs to be edited per dataset.
# ------------------------------------------------------

# TODO: Fix unzip error in `BiocFileCache` download.
# # Download data using `BiocFileCache`.
# data <- bfcrpath(
#   BiocFileCache(tmp_dir, ask = FALSE),
#   "https://transcriptomic-viewer-downloads.s3-us-west-2.amazonaws.com/human/transcriptome.zip"
# )
# unzip(data, exdir = tempdir())

counts <- rbind(
  read_tome_dgCMatrix(file.path(assets_dir, download_name), "data/t_exon"),
  read_tome_dgCMatrix(file.path(assets_dir, download_name), "data/t_intron")
)

sample_name <- read_tome_sample_names(file.path(assets_dir, download_name))
colnames(counts) <- sample_name

gene_name <- read_tome_gene_names(file.path(assets_dir, download_name))
gene_name <- c(gene_name, paste0("intron-", 1:length(gene_name))) # `gene_name` only covers exons.
rownames(counts) <- gene_name

col_data <- fread(file.path(assets_dir, "sample_annotations.csv"), data.table = FALSE)
tsne <- fread(file.path(assets_dir, "2d_coordinates.csv"), data.table = FALSE)

# `tsne` contains fewer samples.
keep <- which(col_data$sample_name %in% tsne$sample_name)
counts <- counts[ , keep]
col_data <- col_data[keep, ]
rownames(col_data) <- NULL
col_data <- cbind(col_data, tsne[ , names(tsne) != "sample_name"])

sce <- SingleCellExperiment(assays = list(counts = counts), colData = col_data)
rm(counts)
sce

# TODO: Suppress "NULL" output.
if (is.null(control_metadata)) {
} else {
  print("Subset to controls.")
  sce <- sce[ , grepl(control_metadata[1], sce[[control_metadata[2]]])]
  sce
}
```

# QC

First, we add cell QC metric metadata to the SCE object.

```{r, qc-metrics}
mito <- grep("^MT-", rownames(sce), ignore.case = TRUE)
if (length(mito) != 0) {
  sce <- addPerCellQC(sce, subsets = list(mito = mito), BPPARAM = MulticoreParam())
  remove <- quickPerCellQC(
    sce, percent_subsets = "subsets_mito_percent", batch = sce[[batch_metadata]]
  )
  if (protocol_type[2] == "single-nuc") {
    print(paste0("Remove ", length(mito), " mitochondrial genes."))
    sce <- sce[-mito, ]
    dim(sce)
  }
} else {
  sce <- addPerCellQC(sce, BPPARAM = MulticoreParam())
  remove <- quickPerCellQC(sce, batch = sce[[batch_metadata]])
}
names(colData(sce))[(length(names(colData(sce))) - 6):length(names(colData(sce)))]
```

We use adaptive thresholds to remove cells that are outliers by more than 3 MADs.

```{r, adaptive-thresholds}
remove <- quickPerCellQC(sce, batch = sce[[batch_metadata]])
sce$discard <- remove$discard
datatable_custom(t(colSums(as.matrix(remove))))

sce <- sce[ , !sce$discard]
dim(sce)
```

Here we carry out any protocol specific techniques, such as identification of empty droplets in a droplet-based experiment.

```{r, protocol-specific}
if (protocol_type[1] == "droplet") {
  # Identify empty droplets as those with a low UMI count.
  bcrank <- barcodeRanks(counts(sce))
  uniq <- !duplicated(bcrank$rank) # Only show unique points for plotting speed.
  plot(
    bcrank$rank[uniq], bcrank$total[uniq], log = "xy",
    xlab = "Rank", ylab = "Total UMI count", cex.lab = 1.2
  )
  abline(h = metadata(bcrank)$inflection, col = "darkgreen", lty = 2)
  abline(h = metadata(bcrank)$knee, col = "dodgerblue", lty = 2)
  legend(
    "bottomleft", legend = c("Inflection", "Knee"), col = c("darkgreen", "dodgerblue"),
    lty = 2, cex = 1.2
  )

  # TODO: Don't stop on "no counts available to estimate the ambient profile" error.
  # set.seed(1)
  # e_out <- emptyDrops(counts(sce))
}
```

Finally we add feature QC metrics and remove features not expressed in any cell.

```{r, feature-qc, fig.height = 7}
sce <- addPerFeatureQC(sce, BPPARAM = MulticoreParam())
names(rowData(sce))
dim(sce)

par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
 log10(rowData(sce)$mean + 1e-6), col = "grey80",  main = "",
 breaks = 40, xlab = "log10(Mean Counts Per Gene + 1e-6)")
hist(
 log10((rowData(sce)$detected * dim(sce)[2]) + 1), col = "grey80", main = "",
 breaks = 40, xlab = "log10(Number of Cells Expressing Gene + 1)")
plot(
 log10(rowData(sce)$mean + 1e-6), pch = 16,
 col = rgb(0, 0, 0, 0.4), log10((rowData(sce)$detected * dim(sce)[2]) + 1),
 xlab = "log10(Mean Counts Per Gene + 1e-6)", ylab = "log10(Number of Cells Expressing Gene + 1)")

sce <- sce[rowSums(counts(sce) > 0) > 0, ]
rowData(sce) <- NULL
sce <- addPerFeatureQC(sce, BPPARAM = MulticoreParam())
dim(sce)

par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
 log10(rowData(sce)$mean + 1e-6), col = "grey80",  main = "",
 breaks = 40, xlab = "log10(Mean Counts Per Gene + 1e-6)")
hist(
 log10((rowData(sce)$detected * dim(sce)[2]) + 1), col = "grey80", main = "",
 breaks = 40, xlab = "log10(Number of Cells Expressing Gene + 1)")
plot(
 log10(rowData(sce)$mean + 1e-6), pch = 16,
 col = rgb(0, 0, 0, 0.4), log10((rowData(sce)$detected * dim(sce)[2]) + 1),
 xlab = "log10(Mean Counts Per Gene + 1e-6)", ylab = "log10(Number of Cells Expressing Gene + 1)")
```

# Cluster Pipeline

We run a pipeline that applies sctransform normalization and scaling, PCA, UMAP reduction, and Louvain clustering.
The following nuisance variables are regressed out: `r vars_to_regress`.

```{r, cluster-pipeline, fig.height = 15, fig.width = 15}
# Remove redundant QC metrics.
if (length(mito) != 0) {
  colData(sce)[length(names(colData(sce)))] <- NULL
  colData(sce)[(length(names(colData(sce))) - 8):(length(names(colData(sce))) - 3)] <- NULL
} else {
  colData(sce)[(length(names(colData(sce))) - 6):length(names(colData(sce)))] <- NULL
}
rowData(sce) <- NULL

sub_name <- "all"
seurat <- as.Seurat(sce, data = NULL)
rm(sce)
seurat <- cluster_pipeline(
  seurat, assets_dir = assets_dir, analysis_no = analysis_no, sub_name = sub_name,
  organism = organism, vars_to_regress = vars_to_regress, parallel_override = parallel_override
)
seurat

for (i in 1:length(metadata_to_plot)) {
  print(metadata_to_plot[i])
  if (i %in% no_legend) {
    print(
      red_dim_plot(seurat, x = "umap1", y = "umap2", color = metadata_to_plot[i], type = "cat") +
        NoLegend()
    )
  } else if (i %in% no_label) {
    print(red_dim_plot(seurat, x = "umap1", y = "umap2", color = metadata_to_plot[i]))
  } else {
    print(red_dim_plot(seurat, x = "umap1", y = "umap2", color = metadata_to_plot[i], type = "cat"))
  }
}
print("nFeature_SCT")
red_dim_plot(seurat, x = "umap1", y = "umap2", color = "nFeature_SCT", type = "cont")
print("nCount_SCT")
red_dim_plot(seurat, x = "umap1", y = "umap2", color = "nCount_SCT", type = "cont")
if (length(mito) != 0) {
  print("subsets_mito_percent")
  red_dim_plot(seurat, x = "umap1", y = "umap2", color = "subsets_mito_percent", type = "cont")
}
```

# References

This is the concluding section of the document. Here we output the `sessionInfo` and create a bibliography for works cited.

```{r, references}
sessionInfo()
```
