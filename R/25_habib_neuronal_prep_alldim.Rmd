---
title: "25 Habib Neuronal Prep All Dimensions"
author:
  - name: "Emir Turkes [emir.turkes@eturkes.com]"
  - name: "UK Dementia Research Institute at UCL"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
bibliography: "../tau-vulnerability.bib"
biblio-style: apalike
link-citations: true
output:
  html_document:
    code_folding: show
    number_sections: true
    theme: lumen
    highlight: haddock
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(
      inputFile, encoding = encoding, output_file = "../results/09-habib-neuronal-alldim.html")})
---

```{r, include = FALSE}
#    This file is part of tau-vulnerability.
#    Copyright (C) 2019  Emir Turkes
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

knitr::opts_chunk$set(fig.width = 8.5, fig.height = 7)
```

<style type="text/css">
body {font-size: 16px;}
h1.title {font-size: 35px;}
h1 {font-size: 24px;}
h2 {font-size: 22px;}
h3 {font-size: 20px;}
.toc-content {padding-left: 0px; padding-right: 0px;}
div.tocify {width: 100%;}
.tocify-subheader .tocify-item {font-size: 0.95em; padding-left: 25px; text-indent: 0;}
div.main-container {max-width: none; width: 100%;}
</style>

*This file is a part of the [Tau Vulnerability Project](https://github.com/eturkes/tau-vulnerability).*

In this document we apply additional processing on the cleaned dataset derived from the analysis in [github.com/eturkes/habib-2017-snRNAseq](https://github.com/eturkes/habib-2017-snRNAseq), which uses droplet-based UMI data from @habib_massively_2017.
Additionally we subset to analyze the neuronal population only.
We start by setting some global variables and loading in any required packages.

```{r}
assets_dir <- file.path(getwd(), "..", "assets")
results_dir <- file.path(getwd(), "..", "results")

packages <- c(
  "conflicted", "SingleCellExperiment", "magrittr", "dplyr", "ggplot2", "ggrepel", "S4Vectors",
  "SummarizedExperiment", "DropletUtils", "scran", "BiocSingular", "scater", "Rtsne", "svd",
  "SC3", "DT", "data.table", "Seurat", "uwot", "viridis")
invisible(suppressPackageStartupMessages(lapply(packages, library, character.only = TRUE)))

conflict_prefer("which", "BiocGenerics")
options(stringsAsFactors = FALSE)

# Create a unique cache and results data directory for each iterated section.
if (!dir.exists(file.path(assets_dir, "cache", "25"))) {
  dir.create(file.path(assets_dir, "cache", "25"), recursive = TRUE)}
if (!dir.exists(file.path(results_dir, "data", "25"))) {
  dir.create(file.path(results_dir, "data", "25"), recursive = TRUE)}

# ggplot2 function providing custom aesthetics and automatic placement of categorical labels.
# For continuous data, a colorbar is implemented.
dim_red_plot <- function(data, x, y, col, type) {
  gg <- ggplot(data, aes_string(x = x, y = y, color = col)) +
    geom_point(alpha = 0.35, stroke = 0.05, shape = 21, aes_string(fill = col)) +
    theme_classic() +
    theme(
      legend.position = "right", plot.title = element_text(hjust = 0.5),
      legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
    if (type == "cat") {
      gg <- gg + geom_label_repel(data = label_df2, aes(label = label), show.legend = FALSE)
    } else if (type == "cont") {
      gg <- ggplot(data, aes_string(x = x, y = y)) +
        geom_point(alpha = 0.35, stroke = 0.05, aes_string(color = col)) +
        theme_classic() +
        theme(
          legend.position = "right", plot.title = element_text(hjust = 0.5),
          legend.title = element_blank()) +
        scale_colour_viridis()}
  gg}
```

# QC

We use a version of the dataset that has not had data removed from the original in order to make a new attempt at QC.

```{r}
sce <- readRDS(file.path(assets_dir, "habib-2017-snRNAseq", "sce_orig.rds"))
sce
```

## Low Quality Nuclei

We remove nuclei overabundant in mitochondrial/ribosomal gene expression, a common indicator of low quality nuclei.

```{r}
mito_drop <- isOutlier(sce$pct_counts_mito, nmads = 3, type = "higher")
ribo_drop <- isOutlier(sce$pct_counts_ribo, nmads = 3, type = "higher")
keep <- !(mito_drop | ribo_drop)
datatable(data.table(
  "By Mitochondrial" = sum(mito_drop), "By Ribosomal" = sum(ribo_drop),
  Remaining = sum(keep)))
sce <- sce[ , keep]
dim(sce)[2]
```

## Lowly Expressed Genes

We consider the expression profile of genes each time nuclei are removed.
A distinctly negative skew can be seen due to lowly expressed genes in our dataset.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

Therefore, we remove genes in the manner specified in @habib_massively_2017.

> A gene is considered detected in a cell if it has at least two unique UMIs (transcripts) associated with it.
For each analysis, genes were removed that were detected in less than 10 nuclei.

```{r}
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

We see a robust improvement in normality.

```{r, fig.height = 5}
sce <- calculateQCMetrics(sce)
par(mfrow = c(1, 3), mar = c(5, 4, 1, 1))
hist(
  log10(rowData(sce)$mean_counts + 1e-6), col = "grey80",  main = "",
  breaks = 40, xlab = "log10(Average Number of UMI + 1e-6)")
hist(
  log10(rowData(sce)$n_cells_by_counts + 1), col = "grey80", main = "",
  breaks = 40, xlab = "log10(Number of Expressed Nuclei + 1)")
plot(
  log10(rowData(sce)$mean_counts + 1e-6), pch = 16,
  col = rgb(0, 0, 0, 0.4), log10(rowData(sce)$n_cells_by_counts + 1),
  xlab = "log10(Average Number of UMI + 1e-6)", ylab = "log10(Number of Expressed Nuclei + 1)")
```

We then display some additional summary statistics.
Apparent is the disproportionately high expression of encoding lncRNAs MALAT1 and MEG3, both of which are known to have higher expression in nuclei, as noted in @habib_massively_2017.

```{r}
plotHighestExprs(sce, exprs_values = "counts")
plotExprsFreqVsMean(sce)
```

## Normalization

We use `computeSumFactors` from the `scran` package to perform normalization.
This function uses a linear deconvolution system to account for expected variation across different cell types/sizes, producing "size factor" values that indicate the extent to which nuclei should be scaled.
We also perform a rough clustering of our nuclei, which improves accuracy on highly heterogenous data such as that from the brain.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

In an experiment where most systematic differences between nuclei are driven by capture efficiency and sequencing depth, we should see a correlation between size factors and library size.

```{r}
sce <- size_factors
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1), bty = "n")
smoothScatter(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts", ylab = "Size Factors")
plot(
  sce$total_counts, sizeFactors(sce), log = "xy", xlab = "Total Counts",
  ylab = "Size Factors", cex = 0.3, pch = 20, col = rgb(0.1, 0.2, 0.7, 0.3))
abline(h = 0.05)
```

The plots are well correlated, confirming the source of bias.
We therefore add normalized expression data to our SCE object using the calculated size factors.
A copy of the SCE object is also saved at this point to capture the QC'd set before subsetting.

```{r}
sce <- normalize(sce)
saveRDS(sce, file.path(results_dir, "data", "25", "sce_orig.rds"))
sce
```

# Subsetting

## First Round

In order to tease out the neuronal population, we start by applying `denoisePCA` from the `scran` package, which can automatically select the number of PCs to retain by modeling technical noise.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  set.seed(1)
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

The results suggest retaining the following number of PCs:

```{r}
sce <- pca
ncol(reducedDim(sce, "PCA"))
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = ncol(reducedDim(sce, "PCA")), lty = 2, col = "red")
```

We use the PCs to compute UMAP coordinates.

```{r}
rds <- file.path(assets_dir, "cache", "25", "denoise_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- runUMAP(sce, min_dist = 0.75)
  saveRDS(umap, rds)}
```

```{r}
sce <- umap
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("denoise_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), denoise_umap1 = add_df$denoise_umap1, denoise_umap2 = add_df$denoise_umap2)

# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", paste0("habib_tsne", 1:2),
    "log10_total_features_by_counts", "habib_cluster_name")],
  add_df)
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_umap1 = median(denoise_umap1), denoise_umap2 = median(denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters denoisePCA UMAP") + theme_linedraw()
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution denoisePCA UMAP") + theme_linedraw()
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("log10(Total Features) denoisePCA UMAP") + theme_linedraw()
```

We see that the PCA method is able to cleanly separate neuronal from non-neuronal cells.
Using the UMAP coordinates, we subset the data.

```{r}
keep <- sce$denoise_umap1 < 0 & sce$denoise_umap2 > -7.5
saveRDS(keep, file.path(results_dir, "data", "25", "keep1.rds"))
sce <- sce[ , keep]
sce
```

We remove genes that are now lowly expressed after the subset.

```{r}
sce <- calculateQCMetrics(sce)
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

Due to the change in dimensions from subsetting, we renormalize.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce <- normalize(sce)
```

And we view the subsetted UMAP figure.

```{r}
# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", paste0("habib_tsne", 1:2), "log10_total_features_by_counts",
    "habib_cluster_name", paste0("denoise_umap", 1:2))])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(denoise_umap1 = median(denoise_umap1), denoise_umap2 = median(denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "denoise_umap1", y = "denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) denoisePCA UMAP")
```

## Second Round

We use `denoisePCA` again to see if the data can be separated by sample origin.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  set.seed(1)
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

```{r}
sce <- pca
ncol(reducedDim(sce, "PCA"))
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = ncol(reducedDim(sce, "PCA")), lty = 2, col = "red")
```

```{r}
rds <- file.path(assets_dir, "cache", "25", "sub_denoise_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- runUMAP(sce, min_dist = 0.05)
  saveRDS(umap, rds)}
```

```{r}
sce <- umap
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("sub_denoise_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), sub_denoise_umap1 = add_df$sub_denoise_umap1,
  sub_denoise_umap2 = add_df$sub_denoise_umap2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(
    sub_denoise_umap1 = median(sub_denoise_umap1), sub_denoise_umap2 = median(sub_denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Habib Clusters Subset denoisePCA UMAP") + theme_linedraw()
dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Sample Distribution Subset denoisePCA UMAP") + theme_linedraw()
dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("log10(Total Features) Subset denoisePCA UMAP") + theme_linedraw()
```

We subset again, only retaining the homogenous portions of the UMAP.

```{r}
keep <- sce$sub_denoise_umap1 > 0
saveRDS(keep, file.path(results_dir, "data", "25", "keep2.rds"))
sce <- sce[ , keep]
sce
```

```{r}
sce <- calculateQCMetrics(sce)
detected_genes <- rowSums(counts(sce) >= 2)
sce <- sce[which(detected_genes >= 10), ]
dim(sce)[1]
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_sub_quickCluster.rds")
if (file.exists(rds)) {
  quickCluster <- readRDS(rds)
} else {
  set.seed(1)
  quickCluster <- quickCluster(sce, use.ranks = FALSE, BSPARAM = IrlbaParam())
  saveRDS(quickCluster, rds)}
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_sub_size_factors.rds")
if (file.exists(rds)) {
  size_factors <- readRDS(rds)
} else {
  size_factors <- computeSumFactors(sce, cluster = quickCluster, min.mean = 0.1)
  saveRDS(size_factors, rds)}
```

```{r}
sce <- normalize(sce)
```

```{r}
# Set up data frame for ggplot2.
gg_df <- data.frame(
  colData(sce)[ , c(
    "cell_id_stem", paste0("habib_tsne", 1:2), "log10_total_features_by_counts",
    "habib_cluster_name", paste0("sub_denoise_umap", 1:2))])
rownames(gg_df) <- NULL
gg_df$habib_cluster_name <- factor(gg_df$habib_cluster_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(
    sub_denoise_umap1 = median(sub_denoise_umap1), sub_denoise_umap2 = median(sub_denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "sub_denoise_umap1", y = "sub_denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) denoisePCA UMAP")
```

# Dimensionality Reduction

## Technical Summation + UMAP

We repeat the `denoisePCA` method once more to assess its effectiveness as this stage for dimensionality reduction.

```{r}
new_trend <- makeTechTrend(x = sce)
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "sub_sub_denoise_pca.rds")
if (file.exists(rds)) {
  pca <- readRDS(rds)
} else {
  set.seed(1)
  pca <- denoisePCA(sce, technical = new_trend, BSPARAM = IrlbaParam())
  saveRDS(pca, rds)}
```

```{r}
sce <- pca
ncol(reducedDim(sce, "PCA"))
par(mfrow = c(1, 1))
plot(
  log10(attr(reducedDim(sce), "percentVar")), xlab = "PC",
  ylab = "log10(Proportion of Variance Explained)", pch = 20,
  cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = ncol(reducedDim(sce, "PCA")), lty = 2, col = "red")
```

```{r}
rds <- file.path(assets_dir, "cache", "25", "sub_sub_denoise_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- runUMAP(sce, min_dist = 0.2)
  saveRDS(umap, rds)}
```

```{r}
sce <- umap
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("sub_sub_denoise_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), sub_sub_denoise_umap1 = add_df$sub_sub_denoise_umap1,
  sub_sub_denoise_umap2 = add_df$sub_sub_denoise_umap2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(
    sub_sub_denoise_umap1 = median(sub_sub_denoise_umap1),
    sub_sub_denoise_umap2 = median(sub_sub_denoise_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_sub_denoise_umap1", y = "sub_sub_denoise_umap2",
  col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Habib Clusters Subset denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "sub_sub_denoise_umap1", y = "sub_sub_denoise_umap2",
  col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution Subset denoisePCA UMAP")
dim_red_plot(
  data = gg_df, x = "sub_sub_denoise_umap1", y = "sub_sub_denoise_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) Subset denoisePCA UMAP")
```

We see that while some relationships are revealed, the results are not entirely satisfactory.

## PPK SVD + UMAP

As an alternative we apply the PROPACK SVD + UMAP combination used in `01_habib_2017_snRNAseq_prep.Rmd`.
This PCA implementation is the foundation of the software GiniClust, which is tailored to reveal rare populations [@hon_human_2018].

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
retain_pcs <- 13
retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = retain_pcs, lty = 2, col = "red")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(1)
  umap <- umap(pca[ , 1:retain_pcs], min_dist = 0.2)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce, "UMAP"))
names(add_df) <- paste0("sub_ppk_umap", seq(ncol(add_df)))
colData(sce) <- cbind(
  colData(sce), sub_ppk_umap1 = add_df$sub_ppk_umap1, sub_ppk_umap2 = add_df$sub_ppk_umap2)
gg_df <- data.frame(gg_df, add_df)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  habib_cluster_name = levels(gg_df$habib_cluster_name),
  label = levels(gg_df$habib_cluster_name))
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(sub_ppk_umap1 = median(sub_ppk_umap1), sub_ppk_umap2 = median(sub_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2",
  col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Whole Set Seurat Clusters Subset PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2", col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution Subset PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_ppk_umap1", y = "sub_ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) PPK UMAP")
```

We find that this approach provides much higher detailed separation than the technical summation approach at this stage.

## HVG

To further reduce noise, we subset the genes to those that are most biologically variable.

```{r}
new_trend <- makeTechTrend(x = sce)
fit <- trendVar(sce, use.spikes = FALSE, loess.args = list(span = 0.05))
fit$trend <- new_trend
dec <- decomposeVar(fit = fit)
top_dec <- rownames(dec[order(dec$bio, decreasing = TRUE), ])[1:10]
rm(fit)
plotExpression(sce, features = top_dec) +
  stat_summary(
    fun.y = median, fun.ymin = median, fun.ymax = median, geom = "crossbar", width = 0.3, alpha = 0.8)

fdr_median <- median(dec$FDR, na.rm = TRUE)
fdr_median
bio_median <- median(dec$bio, na.rm = TRUE)
bio_median

keep <- which(dec$FDR < fdr_median & dec$bio >= bio_median)
sce_hvg <- sce
rm(dec)
dim(sce_hvg)[1]
```

We retain ~3,000 HVGs, a suitable number for our analysis.

### PPK SVD + UMAP

We repeat our preferred dimensionality reduction method from earlier.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "hvg_ppk.rds")
if (file.exists(rds)) {
  ppk <- readRDS(rds)
} else {
  set.seed(1)
  ppk <- propack.svd(scale(t(as.matrix(logcounts(sce_hvg)))), neig = 50)
  saveRDS(ppk, rds)}
```

```{r}
pca <- t(ppk$d * t(ppk$u))
hvg_retain_pcs <- 11
hvg_retain_pcs
par(mfrow = c(1, 1))
plot(
  log10(ppk$d), xlab = "PC", ylab = "log10(Proportion of Variance Explained)",
  pch = 20, cex = 0.6, col = rgb(0.8, 0.2, 0.2, 0.5))
abline(v = hvg_retain_pcs, lty = 2, col = "red")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "hvg_ppk_umap.rds")
if (file.exists(rds)) {
  umap <- readRDS(rds)
} else {
  set.seed(0)
  umap <- umap(pca[ , 1:hvg_retain_pcs], min_dist = 0.2)
  saveRDS(umap, rds)}
```

```{r}
reducedDims(sce_hvg) <- SimpleList(PCA = pca, UMAP = umap)
add_df <- data.frame(reducedDim(sce_hvg, "UMAP"))
names(add_df) <- paste0("sub_hvg_ppk_umap", seq(ncol(add_df)))
colData(sce_hvg) <- cbind(
  colData(sce_hvg), sub_hvg_ppk_umap1 = add_df$sub_hvg_ppk_umap1,
  sub_hvg_ppk_umap2 = add_df$sub_hvg_ppk_umap2)
colData(sce) <- cbind(
  colData(sce), sub_hvg_ppk_umap1 = add_df$sub_hvg_ppk_umap1,
  sub_hvg_ppk_umap2 = add_df$sub_hvg_ppk_umap2)
gg_df <- data.frame(gg_df, add_df)
rm(pca, add_df)

# Setup for automatic placement of cluster labels.
label_df2 <- gg_df %>%
  group_by(habib_cluster_name) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "habib_cluster_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Whole Set Seurat Clusters Subset HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "cell_id_stem", type = "other") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("Sample Distribution Subset HVG PPK UMAP")
dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "log10_total_features_by_counts", type = "cont") +
  xlab("UMAP 1") + ylab("UMAP 2") + ggtitle("log10(Total Features) Subset HVG PPK UMAP")
```

We see that subsetting to HVGs clarifies the UMAP figure, so we use those coordinates for all downstream analysis.

# Clustering

## Seurat

Seurat is a nearest neighbor graph clustering method with a `resolution` parameter that indirectly influences the number of clusters generated.
Concerning `resolution`, the authors write:

> setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells.
Optimal resolution often increases for larger datasets.

As a compromise, we try simply scaling the median of these recommended settings (0.8, which is also the default) to the size of our dataset.
As Seurat typically uses HVGs, we also use `sce_hvg` as input.

```{r}
resolution <- (dim(sce)[2] / 3000) * 0.8
resolution
```

We cluster in the range of $\pm 0.2$ from this resolution.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res_minus0.2.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution - 0.2)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res_minus0.2 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res_minus0.2 = levels(gg_df$hvg_seurat_clusters_res_minus0.2),
  label = levels(gg_df$hvg_seurat_clusters_res_minus0.2))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res_minus0.2) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res_minus0.2", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.1 Resolution Clusters Subset HVG PPK UMAP")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res_minus0.1.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution - 0.1)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res_minus0.1 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res_minus0.1 = levels(gg_df$hvg_seurat_clusters_res_minus0.1),
  label = levels(gg_df$hvg_seurat_clusters_res_minus0.1))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res_minus0.1) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res_minus0.1", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.2 Resolution Clusters Subset HVG PPK UMAP")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res = levels(gg_df$hvg_seurat_clusters_res),
  label = levels(gg_df$hvg_seurat_clusters_res))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.3 Resolution Clusters Subset HVG PPK UMAP")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res_plus0.1.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution + 0.1)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res_plus0.1 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res_plus0.1 = levels(gg_df$hvg_seurat_clusters_res_plus0.1),
  label = levels(gg_df$hvg_seurat_clusters_res_plus0.1))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res_plus0.1) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res_plus0.1", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.4 Resolution Clusters Subset HVG PPK UMAP")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res_plus0.2.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = resolution + 0.2)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res_plus0.2 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res_plus0.2 = levels(gg_df$hvg_seurat_clusters_res_plus0.2),
  label = levels(gg_df$hvg_seurat_clusters_res_plus0.2))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res_plus0.2) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res_plus0.2", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.5 Resolution Clusters Subset HVG PPK UMAP")
```

Inspection of these results reveal that at ~1.3 resolution, optimal results were obtained.
As we would also like a minimally clustered version and one with half as many clusters as our optimal result, we rerun Seurat with the appropriate resolutions below.

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res0.01.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = 0.01)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res0.01 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res0.01 = levels(gg_df$hvg_seurat_clusters_res0.01),
  label = levels(gg_df$hvg_seurat_clusters_res0.01))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res0.01) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res0.01", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat 0.01 Resolution Clusters Subset HVG PPK UMAP")
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "seurat_hvg_res0.2.rds")
if (file.exists(rds)) {
  seurat_hvg <- readRDS(rds)
} else {
  seurat_hvg <- as.Seurat(sce_hvg, counts = "counts", data = NULL)
  seurat_hvg <- NormalizeData(seurat_hvg)
  seurat_hvg <- FindVariableFeatures(seurat_hvg, nfeatures = dim(sce_hvg)[1])
  seurat_hvg <- ScaleData(seurat_hvg, features = rownames(seurat_hvg))
  seurat_hvg <- FindNeighbors(seurat_hvg, reduction = "PCA", dims = 1:hvg_retain_pcs)
  seurat_hvg <- FindClusters(seurat_hvg, resolution = 0.2)
  saveRDS(seurat_hvg, rds)}
```

```{r}
gg_df$hvg_seurat_clusters_res0.2 <- seurat_hvg$seurat_clusters

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res0.2 = levels(gg_df$hvg_seurat_clusters_res0.2),
  label = levels(gg_df$hvg_seurat_clusters_res0.2))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res0.2) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res0.2", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat 0.2 Resolution Clusters Subset HVG PPK UMAP")
```

## SC3

As an alternative, we try clustering using SC3.
First, we estimate the optimal $k$ for our dataset.

```{r}
rowData(sce_hvg)$feature_symbol = rowData(sce_hvg)$external_gene_name
```

```{r, cache = TRUE}
rds <- file.path(assets_dir, "cache", "25", "hvg_sc3_estimate_k.rds")
if (file.exists(rds)) {
  hvg_sc3_estimate_k <- readRDS(rds)
} else {
  set.seed(1)
  hvg_sc3_estimate_k <- sc3_estimate_k(sce_hvg)
  saveRDS(hvg_sc3_estimate_k, rds)}
```

```{r}
sce_hvg <- hvg_sc3_estimate_k
rm(hvg_sc3_estimate_k)
metadata(sce_hvg)$sc3$k_estimation
```

SC3's optimal $k$ seems large compared to Seurat's suggestions, so we generate 2-19 clusters to capture those with Seurat with a margin of error.

```{r}
num_clust <- c(2:19)
counts(sce_hvg) <- as.matrix(counts(sce_hvg))
logcounts(sce_hvg) <- as.matrix(logcounts(sce_hvg))
```

```{r}
# Knitr caching turned off due to:
# Error in lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, compress,  :
# long vectors not supported yet
rds <- file.path(assets_dir, "cache", "25", "hvg_sc3.rds")
if (file.exists(rds)) {
  hvg_sc3 <- readRDS(rds)
} else {
  hvg_sc3 <- sc3(sce_hvg, ks = num_clust, gene_filter = FALSE, biology = TRUE)
  saveRDS(hvg_sc3, rds)}
```

```{r}
sce_hvg <- hvg_sc3
rm(hvg_sc3)

for (i in num_clust) {
  sc3_label <- paste0("sc3_", i, "_clusters")
  hvg_sc3_label <- paste0("hvg_sc3_", i, "_clusters")
  gg_df[[hvg_sc3_label]] <- factor(colData(sce_hvg)[ , sc3_label])}
clusts <- c(paste0("hvg_sc3_", num_clust, "_clusters"))
clusts_nice <- c(paste0("HVG SC3 ", num_clust, " Clusters"))

for (i in 1:length(clusts)) {
  # Setup for automatic placement of cluster labels.
  label_df <- data.frame(tmp = levels(gg_df[[clusts[i]]]), label = levels(gg_df[[clusts[i]]]))
  names(label_df)[names(label_df) == "tmp"] <- clusts[i]
  label_df2 <- gg_df %>%
    group_by_at(clusts[i]) %>%
    summarize(
      sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1),
      sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
    left_join(label_df)

  print(dim_red_plot(
    data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
    col = clusts[i], type = "cat") +
      xlab("UMAP 1") + ylab("UMAP 2") +
      ggtitle(paste("Subset", clusts_nice[i], "Subset HVG PPK UMAP")))}
```

## Labeling

We label the optimal figure at ~1.3 resolution, for now based simply on whether a neuron is excitatory or inhibitory.

```{r}
gg_df$hvg_seurat_clusters_res_name <- NA
hvg_seurat_clusters_res <- as.integer(gg_df$hvg_seurat_clusters_res)
for (i in 1:length(hvg_seurat_clusters_res)) {
  if (hvg_seurat_clusters_res[i] == 1) {
    gg_df[i, ncol(gg_df)] <- "Ex1"
  } else if (hvg_seurat_clusters_res[i] == 2) {
    gg_df[i, ncol(gg_df)] <- "Ex6"
  } else if (hvg_seurat_clusters_res[i] == 3) {
    gg_df[i, ncol(gg_df)] <- "In1"
  } else if (hvg_seurat_clusters_res[i] == 4) {
    gg_df[i, ncol(gg_df)] <- "Ex7"
  } else if (hvg_seurat_clusters_res[i] == 5) {
    gg_df[i, ncol(gg_df)] <- "In3"
  } else if (hvg_seurat_clusters_res[i] == 6) {
    gg_df[i, ncol(gg_df)] <- "In2"
  } else if (hvg_seurat_clusters_res[i] == 7) {
    gg_df[i, ncol(gg_df)] <- "Ex5"
  } else if (hvg_seurat_clusters_res[i] == 8) {
    gg_df[i, ncol(gg_df)] <- "Ex3"
  } else if (hvg_seurat_clusters_res[i] == 9) {
    gg_df[i, ncol(gg_df)] <- "Ex8"
  } else if (hvg_seurat_clusters_res[i] == 10) {
    gg_df[i, ncol(gg_df)] <- "In4"
  } else if (hvg_seurat_clusters_res[i] == 11) {
    gg_df[i, ncol(gg_df)] <- "Ex2"
  } else if (hvg_seurat_clusters_res[i] == 12) {
    gg_df[i, ncol(gg_df)] <- "Ex4"
  } else if (hvg_seurat_clusters_res[i] == 13) {
    gg_df[i, ncol(gg_df)] <- "Ex9"
  } else if (hvg_seurat_clusters_res[i] == 14) {
    gg_df[i, ncol(gg_df)] <- "In5"}}

gg_df$hvg_seurat_clusters_res_name <- factor(gg_df$hvg_seurat_clusters_res_name)
colData(sce) <- cbind(
  colData(sce),
  hvg_seurat_clusters_res = gg_df$hvg_seurat_clusters_res,
  hvg_seurat_clusters_res_name = gg_df$hvg_seurat_clusters_res_name)
colData(sce_hvg) <- cbind(
  colData(sce_hvg),
  hvg_seurat_clusters_res = gg_df$hvg_seurat_clusters_res,
  hvg_seurat_clusters_res_name = gg_df$hvg_seurat_clusters_res_name)

# Setup for automatic placement of cluster labels.
label_df <- data.frame(
  hvg_seurat_clusters_res_name = levels(gg_df$hvg_seurat_clusters_res_name),
  label = levels(gg_df$hvg_seurat_clusters_res_name))
label_df2 <- gg_df %>%
  group_by(hvg_seurat_clusters_res_name) %>%
  summarize(
    sub_hvg_ppk_umap1 = median(sub_hvg_ppk_umap1), sub_hvg_ppk_umap2 = median(sub_hvg_ppk_umap2)) %>%
  left_join(label_df)

dim_red_plot(
  data = gg_df, x = "sub_hvg_ppk_umap1", y = "sub_hvg_ppk_umap2",
  col = "hvg_seurat_clusters_res_name", type = "cat") +
  xlab("UMAP 1") + ylab("UMAP 2") +
  ggtitle("Subset HVG Seurat ~1.3 Resolution Clusters Subset HVG PPK UMAP")
```

# References

This is the concluding section of the document. Here we write relevant results to disk, output the `sessionInfo`, and create a bibliography for works cited.

```{r}
saveRDS(sce, file.path(results_dir, "data", "25", "sce.rds"))
saveRDS(sce_hvg, file.path(results_dir, "data", "25", "sce_hvg.rds"))

sessionInfo()
```
